{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b823de73",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-aggregation\" data-toc-modified-id=\"Data-aggregation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data aggregation</a></span><ul class=\"toc-item\"><li><span><a href=\"#groupby\" data-toc-modified-id=\"groupby-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>groupby</a></span><ul class=\"toc-item\"><li><span><a href=\"#groupby-&amp;-aggregate\" data-toc-modified-id=\"groupby-&amp;-aggregate-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>groupby &amp; aggregate</a></span></li></ul></li><li><span><a href=\"#Pivot-Tables\" data-toc-modified-id=\"Pivot-Tables-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pivot Tables</a></span></li><li><span><a href=\"#Differences-between-pivot-table-and-groupby-function\" data-toc-modified-id=\"Differences-between-pivot-table-and-groupby-function-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Differences between pivot table and groupby function</a></span></li><li><span><a href=\"#crosstab\" data-toc-modified-id=\"crosstab-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>crosstab</a></span></li></ul></li><li><span><a href=\"#Data-combination:-mixing-dataframes\" data-toc-modified-id=\"Data-combination:-mixing-dataframes-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data combination: mixing dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concat:-two-things-together\" data-toc-modified-id=\"Concat:-two-things-together-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Concat: two things together</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concatenating-on-axis-0-(rows)\" data-toc-modified-id=\"Concatenating-on-axis-0-(rows)-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Concatenating on axis 0 (rows)</a></span></li><li><span><a href=\"#Concatenating-on-axis-1-(columns)\" data-toc-modified-id=\"Concatenating-on-axis-1-(columns)-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Concatenating on axis 1 (columns)</a></span></li></ul></li><li><span><a href=\"#Merge:-related-columns\" data-toc-modified-id=\"Merge:-related-columns-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Merge: related columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#LEFT-Merge\" data-toc-modified-id=\"LEFT-Merge-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>LEFT Merge</a></span></li><li><span><a href=\"#RIGHT-Merge\" data-toc-modified-id=\"RIGHT-Merge-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>RIGHT Merge</a></span></li><li><span><a href=\"#INNER-Merge\" data-toc-modified-id=\"INNER-Merge-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>INNER Merge</a></span></li><li><span><a href=\"#OUTER-Merge\" data-toc-modified-id=\"OUTER-Merge-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>OUTER Merge</a></span></li></ul></li><li><span><a href=\"#Merging-&amp;-Concatenating-in-two-different-columns\" data-toc-modified-id=\"Merging-&amp;-Concatenating-in-two-different-columns-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Merging &amp; Concatenating in two different columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concatenating-in-two-different-columns\" data-toc-modified-id=\"Concatenating-in-two-different-columns-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Concatenating in two different columns</a></span></li><li><span><a href=\"#Merging-in-two-different-columns\" data-toc-modified-id=\"Merging-in-two-different-columns-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Merging in two different columns</a></span></li></ul></li><li><span><a href=\"#Join:-relating-index\" data-toc-modified-id=\"Join:-relating-index-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Join: relating index</a></span></li><li><span><a href=\"#Differences-between-join-&amp;-merge\" data-toc-modified-id=\"Differences-between-join-&amp;-merge-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Differences between join &amp; merge</a></span></li></ul></li><li><span><a href=\"#Pandas-usual-methods\" data-toc-modified-id=\"Pandas-usual-methods-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pandas usual methods</a></span></li><li><span><a href=\"#Further-materials\" data-toc-modified-id=\"Further-materials-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Further materials</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d0378",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1400/1*6d5dw6dPhy4vBp2vRW6uzw.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4670f9",
   "metadata": {},
   "source": [
    "Primero, importamos las librerías principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbfec44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af75b7d",
   "metadata": {},
   "source": [
    "Cargamos un nuevo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998423db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/employees.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2050b9",
   "metadata": {},
   "source": [
    "what is it about? Let's look at it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1f24d",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "La agregación de datos es una técnica fundamental en el análisis de datos que implica agrupar y resumir datos para obtener información y tomar decisiones informadas. En esta sección, exploraremos métodos esenciales de Pandas para la agregación de datos, incluyendo `groupby`, `pivot_table` y `crosstab`.\n",
    "\n",
    "Estas técnicas son particularmente útiles cuando se trata de grandes conjuntos de datos o cuando necesitas resumir datos a través de diferentes categorías o dimensiones. Ya sea que quieras calcular estadísticas para grupos específicos, crear tablas resumen o analizar relaciones entre variables, los métodos de agregación de datos en Pandas proporcionan las herramientas para agilizar tu análisis.\n",
    "\n",
    "Vamos a sumergirnos en cada uno de estos métodos y descubrir cómo pueden ayudarte a descubrir patrones y tendencias significativas dentro de tus datos.\n",
    "\n",
    "### groupby\n",
    "\n",
    "Pandas GroupBy es una función poderosa y versátil en Python que es indispensable para la manipulación y análisis de datos. Nos permite dividir un DataFrame en grupos separados basados en uno o más criterios y realizar varios cálculos sobre estos grupos para un análisis profundo.\n",
    "\n",
    "El concepto es sencillo: seleccionas un DataFrame, especificas las categorías o criterios por los cuales quieres agrupar tus datos, y luego aplicas funciones de agregación a cada grupo. Estas funciones de agregación pueden incluir cálculos como sumar, promediar, contar, o incluso funciones definidas por el usuario, dependiendo de tus objetivos de análisis.\n",
    "\n",
    "Las operaciones de GroupBy son invaluables para tareas como resumir datos, explorar patrones dentro de grupos específicos, o comparar diferentes segmentos de tu conjunto de datos. Ya estés trabajando con datos de ventas, comportamiento del cliente, o cualquier otro tipo de datos estructurados, Pandas GroupBy es tu herramienta de elección.\n",
    "\n",
    "Aquí tienes una sintaxis básica para usar GroupBy:\n",
    "\n",
    "`df[subset].groupby(category).aggregation()`\n",
    "\n",
    "Para profundizar en las capacidades y opciones de Pandas GroupBy, puedes referirte a la documentación oficial [aquí](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c6bb3",
   "metadata": {},
   "source": [
    "`groupby the departments and their mean age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3877a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo (1st)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo (2nd)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").agg(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968b6e9",
   "metadata": {},
   "source": [
    "`groupby the departments and their maximum age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo (1st)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").agg({\"Age\":\"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62424b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo (2nd)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28133159",
   "metadata": {},
   "source": [
    "`groupby the departments and their min age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo  (1st)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").agg({\"Age\":\"min\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a966a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay dos formas de hacerlo  (2nd)\n",
    "df[[\"Age\", \"Department\"]].groupby(\"Department\").min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08947d4b",
   "metadata": {},
   "source": [
    "`groupby: 2+`: Diferentes campos de educación y sus salarios medios en cada uno de los departamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"EducationField\", \"HourlyRate\", \"Department\"]].groupby(by=[\"Department\", \"EducationField\"]).agg({\"HourlyRate\":\"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad439933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"EducationField\", \"HourlyRate\", \"Department\"]].groupby(by=[\"EducationField\", \"Department\"]).agg({\"HourlyRate\":\"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13345cef",
   "metadata": {},
   "source": [
    "`more fields`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"EducationField\", \"HourlyRate\", \"Department\", \"StandardHours\", \"Age\"]].groupby(by=[\"Department\", \"EducationField\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b533d07",
   "metadata": {},
   "source": [
    "#### groupby & aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930acad",
   "metadata": {},
   "source": [
    "En Pandas, la función \"agg\" se utiliza para agregar datos dentro de los grupos creados mediante GroupBy. Permite aplicar múltiples funciones de agregación a la vez, ofreciendo un control detallado sobre el resumen de tus datos.\n",
    "\n",
    "Estas son algunas funciones de agregación comunes disponibles con \"agg\":\n",
    "- **mean**: Calcula el promedio de los valores en cada grupo.\n",
    "- **sum**: Suma todos los valores en cada grupo.\n",
    "- **count**: Cuenta el número de filas en cada grupo.\n",
    "\n",
    "Con \"agg\", puedes especificar estas y otras funciones de agregación, adaptando el resumen de tus datos a tus necesidades específicas de análisis. Esta capacidad es muy útil cuando necesitas obtener distintas estadísticas de tus datos agrupados al mismo tiempo.\n",
    "\n",
    "Para más detalles sobre la función \"agg\" y sus opciones avanzadas, puedes consultar la documentación oficial de Pandas [aquí](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html).\n",
    "\n",
    "### Tablas dinámicas\n",
    "\n",
    "Las tablas dinámicas son esenciales en análisis de datos, especialmente cuando necesitas analizar y comparar varios aspectos de tu conjunto de datos de manera simultánea. Pandas ofrece la función `pivot_table`, que permite crear tablas dinámicas estilo hoja de cálculo dentro de un DataFrame.\n",
    "\n",
    "La función `pivot_table` acepta varios parámetros clave:\n",
    "- `df`: El DataFrame que deseas pivotar.\n",
    "- `values`: Las columnas que contienen los valores para agregar.\n",
    "- `index`: Las columnas que se convertirán en el nuevo índice de la tabla dinámica.\n",
    "- `columns`: Las columnas que se convertirán en las nuevas columnas de la tabla dinámica.\n",
    "- `aggfunc`: La función de agregación que se aplicará a los valores (el valor por defecto es 'mean').\n",
    "\n",
    "Al aplicar `pivot_table`, tu data se organiza en un formato más estructurado, facilitando operaciones de agregación como el cálculo de medias, sumas o conteos a través de diferentes grupos y dimensiones.\n",
    "\n",
    "Para una guía detallada sobre cuándo usar `groupby` en comparación con `pivot_table`, puedes revisar el siguiente artículo: [GroupBy vs. Pivot Table](https://towardsdatascience.com/a-comparison-of-groupby-and-pivot-in-pythons-pandas-module-527909e78d6b).\n",
    "\n",
    "Aprovechar las tablas dinámicas puede mejorar significativamente tu análisis de datos, ayudándote a descubrir insights en conjuntos de datos complejos.\n",
    "\n",
    "Para conocer más sobre `pivot_table` y sus opciones avanzadas, consulta la documentación oficial de Pandas [aquí](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html).\n",
    "\n",
    "`tabla dinámica`: el departamento y sus edades medias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f601835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo, calculando media de edad por departamento\n",
    "df.pivot_table(\n",
    "    values = \"Age\",\n",
    "    index = \"Department\",\n",
    "    aggfunc = \"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17fa4b",
   "metadata": {},
   "source": [
    "Now, is your **turn**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e6d7f",
   "metadata": {},
   "source": [
    "`pivot table`: el departamento y sus edades max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b920ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23fdbbe2",
   "metadata": {},
   "source": [
    "`pivot table`: el departamento y sus edades min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c804160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b08ccf2",
   "metadata": {},
   "source": [
    "`pivot table`: el departamento y media de edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc473f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e9e0c6",
   "metadata": {},
   "source": [
    "`multi-index pivot table`: salario máximo de los empleados por departamento y campo de educación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example, calculating mean age by department and EducationField\n",
    "\n",
    "df.pivot_table (\n",
    "    values = \"MonthlyIncome\",\n",
    "    index = [\"Department\", \"EducationField\"],\n",
    "    aggfunc = \"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b715869",
   "metadata": {},
   "source": [
    "### crosstab\n",
    "\n",
    "En el análisis de datos, comprender las relaciones entre variables categóricas es a menudo crucial para obtener insights sobre tu conjunto de datos. Pandas ofrece una herramienta llamada `crosstab` que te ayuda a computar una simple tabulación cruzada de dos o más factores dentro de tu DataFrame.\n",
    "\n",
    "La función `pd.crosstab()` está diseñada para este propósito y es particularmente útil cuando quieres examinar la frecuencia o distribución de una variable categórica en relación con otra. Por defecto, computa una tabla de frecuencia, pero también puedes pasar un arreglo de valores y una función de agregación para análisis más avanzados.\n",
    "\n",
    "Sintaxys basica:\n",
    "```python\n",
    "pd.crosstab(df[column1], df[column2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46987cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example I\n",
    "pd.crosstab(df[\"Department\"], df[\"EducationField\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example II\n",
    "pd.crosstab(df[\"Department\"], df[\"EducationField\"], df[\"MonthlyIncome\"], aggfunc=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465cda9",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c1560",
   "metadata": {},
   "source": [
    "## Combinación de datos: mezclando dataframes\n",
    "\n",
    "En el análisis de datos del mundo real, a menudo te encuentras con escenarios donde necesitas combinar datos de diferentes fuentes u organizarlos de manera diferente para realizar un análisis significativo. Pandas proporciona varios métodos potentes para fusionar, unir y concatenar DataFrames que te ayudan a gestionar este proceso de manera eficiente.\n",
    "\n",
    "Para una comprensión completa de estas técnicas, considera explorar los siguientes recursos:\n",
    "- [Real Python: Pandas Merge, Join, y Concat](https://realpython.com/pandas-merge-join-and-concat/)\n",
    "- [Documentación de Pandas: Fusión y Unión](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "### Concat: dos cosas juntas\n",
    "La concatenación es una de las operaciones fundamentales para combinar DataFrames. Con `pd.concat()`, puedes unir DataFrames a lo largo de un eje especificado, usualmente a lo largo del eje 0 (verticalmente), para apilarlos uno debajo del otro. Esto alinea las columnas basadas en sus etiquetas, lo que lo convierte en una herramienta valiosa para extender o añadir datos verticalmente.\n",
    "\n",
    "La sintaxis básica para la concatenación es la siguiente:\n",
    "```python\n",
    "result = pd.concat([df1, df2, ...], axis=0)\n",
    "```\n",
    "Aquí, `df1`, `df2`, y así sucesivamente son los DataFrames que quieres concatenar. El argumento `axis=0` asegura que la concatenación ocurra verticalmente, alineando las filas.\n",
    "\n",
    "Dominando la concatenación, puedes gestionar de manera eficiente conjuntos de datos que crecen con el tiempo o combinar datos de varias fuentes en un único DataFrame cohesivo. Esto es particularmente útil cuando se trata de datos de series temporales, archivos de registro u otras situaciones donde los datos se recopilan de manera incremental.\n",
    "\n",
    "Para profundizar más en la concatenación y explorar opciones más avanzadas, puedes referirte a los recursos proporcionados y la documentación oficial de Pandas sobre [pd.concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac484cd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load some data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user',\n",
    "                             sep='|', \n",
    "                             index_col='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63950f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sample it\n",
    "first_df = df.sample(frac=0.1)\n",
    "second_df = df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac7695b",
   "metadata": {},
   "source": [
    "#### Concatenating on axis 0 (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6af3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([first_df, second_df], axis=0, keys=[\"Table 1\", \"Table 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80517add",
   "metadata": {},
   "source": [
    "- Esta operación concatena los DataFrames `first_df` y `second_df` verticalmente (a lo largo de `axis=0`), lo que significa que los apila uno encima del otro.\n",
    "\n",
    "- El parámetro `keys` se utiliza para especificar un índice jerárquico para el DataFrame resultante. En este caso, estás dando a cada DataFrame original una etiqueta: \"Tabla 1\" y \"Tabla 2\".\n",
    "\n",
    "- Como resultado, la salida será un nuevo DataFrame con una estructura jerárquica (MultiIndex). Puedes pensar en ello como tener dos secciones etiquetadas \"Tabla 1\" y \"Tabla 2\", donde cada sección contiene los datos del respectivo DataFrame original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d00f5",
   "metadata": {},
   "source": [
    "#### Concatenating on axis 1 (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7118492",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([first_df, second_df], axis=1, keys=[\"left\", \"right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274d6cf",
   "metadata": {},
   "source": [
    "- Esta operación concatena los DataFrames `first_df` y `second_df` horizontalmente (a lo largo de `axis=1`), lo que significa que los combina uno al lado del otro.\n",
    "\n",
    "- Similar a la primera operación, el parámetro `keys` se utiliza para etiquetar las columnas resultantes de cada DataFrame original. Aquí, las estás etiquetando como \"izquierda\" y \"derecha\".\n",
    "\n",
    "- La salida será un nuevo DataFrame donde las columnas están organizadas en dos secciones etiquetadas \"izquierda\" y \"derecha\", representando los datos de los respectivos DataFrames originales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd65ff4",
   "metadata": {},
   "source": [
    "![sql joins](https://upload.wikimedia.org/wikipedia/commons/9/9d/SQL_Joins.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-klein",
   "metadata": {},
   "source": [
    "### Merge: related columns\n",
    "\n",
    "La función `merge()` en Pandas es una herramienta poderosa cuando necesitas combinar filas de múltiples DataFrames basados en columnas relacionadas. Se utiliza principalmente para uniones al estilo de bases de datos donde quieres reunir datos de diferentes fuentes que comparten columnas clave comunes.\n",
    "\n",
    "**Entendiendo la Función `merge()`**:\n",
    "\n",
    "Puedes pensar en la función `merge()` como una manera de fusionar filas que comparten datos a través de columnas especificadas. Te permite realizar varios tipos de uniones, como uniones internas, externas, izquierdas y derechas, que determinan cómo se combinan las filas de ambos DataFrames.\n",
    "\n",
    "- **Unión Interna (Inner Join)**: Este tipo de unión devuelve solo las filas donde hay una coincidencia en ambos DataFrames basada en las columnas especificadas. Las filas sin coincidencia se excluyen.\n",
    "\n",
    "- **Unión Externa (Full Outer Join)**: Una unión externa devuelve todas las filas cuando hay una coincidencia en cualquiera de los DataFrames izquierdo o derecho. Las filas no emparejadas contendrán valores NaN para los datos faltantes.\n",
    "\n",
    "- **Unión Izquierda (Left Outer Join)**: Una unión izquierda devuelve todas las filas del DataFrame izquierdo y las filas emparejadas del DataFrame derecho. Las filas no emparejadas del DataFrame izquierdo aún se incluirán.\n",
    "\n",
    "- **Unión Derecha (Right Outer Join)**: A la inversa, una unión derecha devuelve todas las filas del DataFrame derecho y las filas emparejadas del DataFrame izquierdo. Las filas no emparejadas del DataFrame derecho aún se incluirán.\n",
    "\n",
    "**Uso y Sintaxis**:\n",
    "\n",
    "Aquí tienes un esquema básico de cómo usar la función `merge()`:\n",
    "\n",
    "```python\n",
    "merged_df = pd.merge(left_df, right_df, on='common_column', how='join_type')\n",
    "```\n",
    "- **Uso y Sintaxis:**\n",
    "\n",
    "  - `left_df`: El DataFrame izquierdo que quieres fusionar.\n",
    "  - `right_df`: El DataFrame derecho que quieres fusionar.\n",
    "  - `on`: La(s) columna(s) en las que quieres realizar la fusión. Estas columnas deberían existir en ambos DataFrames y servir como la(s) clave(s) para la operación de fusión.\n",
    "  - `how`: El tipo de unión que quieres realizar (por ejemplo, 'inner', 'outer', 'left', 'right').\n",
    "\n",
    "- **Beneficios de Usar `merge()`:**\n",
    "\n",
    "  - **Integración de Datos:** Merge ayuda a integrar datos de múltiples fuentes o tablas en un conjunto de datos único y comprensivo.\n",
    "\n",
    "  - **Análisis de Datos:** Simplifica el proceso de combinar información relacionada, facilitando el análisis de datos y la derivación de insights.\n",
    "\n",
    "  - **Operaciones de Base de Datos:** `merge()` se alinea con operaciones comunes de bases de datos como las uniones SQL, permitiendo a los analistas de datos aprovechar su conocimiento de SQL dentro de Pandas.\n",
    "\n",
    "  - **Consultas Complejas:** Puedes manejar relaciones de datos complejas y realizar consultas que involucren múltiples tablas de manera eficiente.\n",
    "\n",
    "Fusionar DataFrames usando `merge()` es una operación fundamental en la manipulación y análisis de datos, especialmente cuando se trata de conjuntos de datos del mundo real de diversas fuentes. Te proporciona la flexibilidad para controlar cómo se combinan los datos y te permite trabajar con relaciones de datos complejas.\n",
    "\n",
    "Para obtener información más detallada y opciones, puedes referirte a la documentación oficial de Pandas sobre [`merge()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c38f1",
   "metadata": {},
   "source": [
    "#### LEFT Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n",
    "        \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n",
    "        \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        \"key1\": [\"K90\", \"K1\", \"K1\", \"K2\"],\n",
    "        \"key2\": [\"K0\", \"K0\", \"K5\", \"K0\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"Y\": [\"D0\", \"D70\", \"D2\", \"D5\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0378289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just showing tables\n",
    "df1_styler = df1.style.set_table_attributes(\"style='display:inline'\").set_caption('Left table')\n",
    "df2_styler = df2.style.set_table_attributes(\"style='display:inline'\").set_caption('Right table')\n",
    "display_html(df1_styler._repr_html_() + \" \" + df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge, default is inner\n",
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793eb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges, now is a left\n",
    "pd.merge(df1, df2, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges, now is a right\n",
    "pd.merge(df1, df2, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a42620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge, now is inner\n",
    "pd.merge(df1, df2, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade57982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge, now is outer\n",
    "outer_merge = pd.merge(df1, df2, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce32d1",
   "metadata": {},
   "source": [
    "### Merging & Concatenating in two different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_docs = pd.DataFrame({'Locations': ['Spain', 'France', 'Portugal', 'Spain'],\n",
    "                    'city': [\"Barcelona\", \"Paris\", \"Lisbon\", \"Madrid\"]})\n",
    "df2_docs = pd.DataFrame({'More locations': ['Spain', 'France', 'Portugal', 'Spain'],\n",
    "                    'city': [\"Madrid\", \"Lyon\", \"Porto\", \"Albacete\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda9802",
   "metadata": {},
   "source": [
    "#### Concatenating in two different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1_docs, df2_docs], axis=1, keys=[\"1st table\", \"2nd table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a8141",
   "metadata": {},
   "source": [
    "#### Merging in two different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_docs.merge(df2_docs, left_on='Locations', right_on='More locations', suffixes = [\"_fromlastyear\", \"_fromthisyear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_docs.merge(df2_docs,  left_on='Locations', right_on='More locations', suffixes = [\"_fromleft\", \"_fromright\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e952e34",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Join: relating index\n",
    "The join, unlike the merge, will join the dataframes and where there are no records in the \"index\" it will put NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4660ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd   \n",
    "from IPython.display import display_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56efa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = pd.DataFrame({\"A\": [\"A0\", \"A1\", \"A2\"], \"B\": [\"B0\", \"B1\", \"B2\"]}, index=[\"K0\", \"K1\", \"K2\"])\n",
    "right_df = pd.DataFrame({\"C\": [\"C0\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D2\", \"D3\"]}, index=[\"K0\", \"K2\", \"K3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df.join(right_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad1415",
   "metadata": {},
   "source": [
    "### Diferencias entre join y merge\n",
    "Al combinar DataFrames en Pandas, tienes dos métodos principales a tu disposición: `join()` y `merge()`. Cada método tiene su propio conjunto de características y casos de uso. A continuación, se presenta una comparación de estos dos métodos basada en diferentes características de unión:\n",
    "\n",
    "| Característica de Unión             | `join()` | `merge()` |\n",
    "|-------------------------------------|:--------:|:---------:|\n",
    "| Unión Interna (Inner Join)          |   Sí     |    Sí     |\n",
    "| Unión Izquierda (Left Join)         |   Sí     |    Sí     |\n",
    "| Unión Derecha (Right Join)          |   Sí     |    Sí     |\n",
    "| Unión Externa (Outer Join)          |   Sí     |    Sí     |\n",
    "| Unión Cruzada (Cross Join)          |    X     |    Sí     |\n",
    "| Unión en Índices                    |   Sí     |    Sí     |\n",
    "| Unión en Columnas                   |    X     |    Sí     |\n",
    "| Izquierda en Columna, Derecha en Índice |   Sí  |    Sí     |\n",
    "| Izquierda en Índice, Derecha en Columna |    X  |    Sí     |\n",
    "\n",
    "**Explicación:**\n",
    "\n",
    "- **Unión Interna (Inner Join):** Tanto `join()` como `merge()` admiten uniones internas, que devuelven solo las filas con valores coincidentes en ambos DataFrames.\n",
    "\n",
    "- **Unión Izquierda (Left Join):** Ambos métodos permiten uniones izquierdas, que incluyen todas las filas del DataFrame izquierdo y las filas coincidentes del DataFrame derecho.\n",
    "\n",
    "- **Unión Derecha (Right Join):** Ambos métodos admiten uniones derechas, que incluyen todas las filas del DataFrame derecho y las filas coincidentes del DataFrame izquierdo.\n",
    "\n",
    "- **Unión Externa (Outer Join):** Ambos métodos permiten uniones externas, que incluyen todas las filas de ambos DataFrames, rellenando los valores faltantes con NaN donde sea necesario.\n",
    "\n",
    "- **Unión Cruzada (Cross Join):** Mientras que `merge()` puede realizar uniones cruzadas, `join()` no las admite. Las uniones cruzadas resultan en un producto cartesiano de filas entre dos DataFrames.\n",
    "\n",
    "- **Unión en Índices:** Tanto `join()` como `merge()` pueden realizar uniones basadas en el índice de los DataFrames.\n",
    "\n",
    "- **Unión en Columnas:** `merge()` permite unir DataFrames en columnas específicas, mientras que `join()` no ofrece esta capacidad.\n",
    "\n",
    "- **Izquierda en Columna, Derecha en Índice:** Ambos métodos admiten la unión en una columna del DataFrame izquierdo y el índice del DataFrame derecho.\n",
    "\n",
    "- **Izquierda en Índice, Derecha en Columna:** `merge()` puede unir en el índice del DataFrame izquierdo y una columna del DataFrame derecho, pero `join()` no ofrece esta opción.\n",
    "\n",
    "Esta comparación debería ayudarte a elegir el método apropiado basado en tus requisitos específicos de fusión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979ee71",
   "metadata": {},
   "source": [
    "## Business challenge: IronHack Delivery orders analysis (use pycharm)\n",
    "\n",
    "En este análisis, exploraremos un conjunto de datos que contiene información sobre pedidos de socios falsos dentro de la aplicación. Los socios falsos son tiendas no integradas directamente con Glovo, y nuestro equipo de contenido gestiona su catálogo de productos y precios. Este conjunto de datos proporciona detalles sobre los pedidos, discrepancias de pago y otra información relevante.\n",
    "\n",
    "1. Descripción del Conjunto de Datos\n",
    "    - `order_id`: Identificador único para cada pedido.\n",
    "    - `activation_time_local`: Hora local cuando se activó el pedido.\n",
    "    - `country_code`: Código de país para el pedido.\n",
    "    - `store_address`: Dirección de la tienda.\n",
    "    - `final_status`: El estado final del pedido.\n",
    "    - `payment_status`: El estado de pago del pedido.\n",
    "    - `products`: Número de productos en el pedido.\n",
    "    - `products_total`: Monto total en el momento de la compra en euros (€).\n",
    "    - `purchase_total_price`: Monto que el mensajero pagó en la tienda en euros (€).\n",
    "\n",
    "2. Antecedentes\n",
    "Los pedidos de socios falsos pueden exhibir discrepancias entre el monto total en el momento de la compra (`products_total`) y el monto que el mensajero paga en la tienda (`purchase_total_price`). Cuando `products_total` es menor que `purchase_total_price`, los clasificamos como \"pedidos no autorizados suficientemente\". Entender estas discrepancias es crucial para la transición de cobro contra entrega a un modelo de autorización y captura.\n",
    "\n",
    "3. Preguntas Clave\n",
    "Durante este proceso de Análisis Exploratorio de Datos (EDA), apuntamos a responder las siguientes preguntas:\n",
    "\n",
    "    1. ¿Qué porcentaje de pedidos no están suficientemente autorizados?\n",
    "    2. ¿Qué porcentaje de pedidos estarían correctamente autorizados con una autorización incremental del 20% sobre el monto en el momento de la compra?\n",
    "    3. ¿Existen diferencias en los porcentajes anteriores cuando se dividen por país?\n",
    "    4. Para los pedidos restantes fuera de la autorización incremental, ¿qué valores serían necesarios para capturar el monto restante?\n",
    "    5. ¿Cuáles son las tiendas más problemáticas en términos de pedidos y valor monetario?\n",
    "    6. Para los pedidos no autorizados suficientemente, ¿existe una correlación entre la diferencia de precio y las cancelaciones de pedidos? En otras palabras, ¿es más probable que un pedido sea cancelado a medida que aumenta la diferencia de precio?\n",
    "\n",
    "A través de este análisis, apuntamos a obtener insights sobre las fluctuaciones de precios de pedidos pasados y evaluar el riesgo asociado con la transición a un nuevo modelo de autorización.\n",
    "\n",
    "¡Sumérgete en el conjunto de datos y comienza a explorar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2e6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./datasets/fake_orders_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ae261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33557880</th>\n",
       "      <th>2019-03-10 23:59:59.000000</th>\n",
       "      <th>AR</th>\n",
       "      <th>14200</th>\n",
       "      <th>DeliveredStatus</th>\n",
       "      <th>PAID</th>\n",
       "      <th>1</th>\n",
       "      <th>4.54</th>\n",
       "      <th>8.64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33512615</td>\n",
       "      <td>2019-03-10 23:58:32.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33512451</td>\n",
       "      <td>2019-03-10 23:57:56.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33530892</td>\n",
       "      <td>2019-03-10 23:57:33.000000</td>\n",
       "      <td>ES</td>\n",
       "      <td>19777</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33557765</td>\n",
       "      <td>2019-03-10 23:57:21.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>34565</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33512273</td>\n",
       "      <td>2019-03-10 23:57:13.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>63536</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>4</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   33557880  2019-03-10 23:59:59.000000  AR  14200  DeliveredStatus  PAID  1  \\\n",
       "0  33512615  2019-03-10 23:58:32.000000  TR  28725  DeliveredStatus  PAID  1   \n",
       "1  33512451  2019-03-10 23:57:56.000000  TR  28725  DeliveredStatus  PAID  1   \n",
       "2  33530892  2019-03-10 23:57:33.000000  ES  19777   CanceledStatus  PAID  1   \n",
       "3  33557765  2019-03-10 23:57:21.000000  AR  34565  DeliveredStatus  PAID  2   \n",
       "4  33512273  2019-03-10 23:57:13.000000  TR  63536  DeliveredStatus  PAID  4   \n",
       "\n",
       "    4.54  8.64  \n",
       "0   3.76  3.76  \n",
       "1   2.86  2.86  \n",
       "2  12.95  0.00  \n",
       "3   2.86  6.48  \n",
       "4   1.88  1.96  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef09ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['order_id', 'activation_time_local', 'country_code', 'store_address',\n",
    "            'final_status', 'payment_status', 'products', 'products_total',\n",
    "            'purchase_total_price']\n",
    "df.columns = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f601880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>activation_time_local</th>\n",
       "      <th>country_code</th>\n",
       "      <th>store_address</th>\n",
       "      <th>final_status</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>products</th>\n",
       "      <th>products_total</th>\n",
       "      <th>purchase_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33512615</td>\n",
       "      <td>2019-03-10 23:58:32.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33512451</td>\n",
       "      <td>2019-03-10 23:57:56.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33530892</td>\n",
       "      <td>2019-03-10 23:57:33.000000</td>\n",
       "      <td>ES</td>\n",
       "      <td>19777</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33557765</td>\n",
       "      <td>2019-03-10 23:57:21.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>34565</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33512273</td>\n",
       "      <td>2019-03-10 23:57:13.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>63536</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>4</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id       activation_time_local country_code  store_address  \\\n",
       "0  33512615  2019-03-10 23:58:32.000000           TR          28725   \n",
       "1  33512451  2019-03-10 23:57:56.000000           TR          28725   \n",
       "2  33530892  2019-03-10 23:57:33.000000           ES          19777   \n",
       "3  33557765  2019-03-10 23:57:21.000000           AR          34565   \n",
       "4  33512273  2019-03-10 23:57:13.000000           TR          63536   \n",
       "\n",
       "      final_status payment_status  products  products_total  \\\n",
       "0  DeliveredStatus           PAID         1            3.76   \n",
       "1  DeliveredStatus           PAID         1            2.86   \n",
       "2   CanceledStatus           PAID         1           12.95   \n",
       "3  DeliveredStatus           PAID         2            2.86   \n",
       "4  DeliveredStatus           PAID         4            1.88   \n",
       "\n",
       "   purchase_total_price  \n",
       "0                  3.76  \n",
       "1                  2.86  \n",
       "2                  0.00  \n",
       "3                  6.48  \n",
       "4                  1.96  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d689daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60399 entries, 0 to 60398\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   order_id               60399 non-null  int64  \n",
      " 1   activation_time_local  60399 non-null  object \n",
      " 2   country_code           60399 non-null  object \n",
      " 3   store_address          60399 non-null  int64  \n",
      " 4   final_status           60399 non-null  object \n",
      " 5   payment_status         60399 non-null  object \n",
      " 6   products               60399 non-null  int64  \n",
      " 7   products_total         60399 non-null  float64\n",
      " 8   purchase_total_price   60399 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc91b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                 0\n",
       "activation_time_local    0\n",
       "country_code             0\n",
       "store_address            0\n",
       "final_status             0\n",
       "payment_status           0\n",
       "products                 0\n",
       "products_total           0\n",
       "purchase_total_price     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffe5697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>activation_time_local</th>\n",
       "      <th>country_code</th>\n",
       "      <th>store_address</th>\n",
       "      <th>final_status</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>products</th>\n",
       "      <th>products_total</th>\n",
       "      <th>purchase_total_price</th>\n",
       "      <th>discrepancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33512615</td>\n",
       "      <td>2019-03-10 23:58:32.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33512451</td>\n",
       "      <td>2019-03-10 23:57:56.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33530892</td>\n",
       "      <td>2019-03-10 23:57:33.000000</td>\n",
       "      <td>ES</td>\n",
       "      <td>19777</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33557765</td>\n",
       "      <td>2019-03-10 23:57:21.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>34565</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33512273</td>\n",
       "      <td>2019-03-10 23:57:13.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>63536</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>4</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id       activation_time_local country_code  store_address  \\\n",
       "0  33512615  2019-03-10 23:58:32.000000           TR          28725   \n",
       "1  33512451  2019-03-10 23:57:56.000000           TR          28725   \n",
       "2  33530892  2019-03-10 23:57:33.000000           ES          19777   \n",
       "3  33557765  2019-03-10 23:57:21.000000           AR          34565   \n",
       "4  33512273  2019-03-10 23:57:13.000000           TR          63536   \n",
       "\n",
       "      final_status payment_status  products  products_total  \\\n",
       "0  DeliveredStatus           PAID         1            3.76   \n",
       "1  DeliveredStatus           PAID         1            2.86   \n",
       "2   CanceledStatus           PAID         1           12.95   \n",
       "3  DeliveredStatus           PAID         2            2.86   \n",
       "4  DeliveredStatus           PAID         4            1.88   \n",
       "\n",
       "   purchase_total_price  discrepancia  \n",
       "0                  3.76          0.00  \n",
       "1                  2.86          0.00  \n",
       "2                  0.00         12.95  \n",
       "3                  6.48         -3.62  \n",
       "4                  1.96         -0.08  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"discrepancia\"] = df[\"products_total\"] - df[\"purchase_total_price\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce5e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.58373483004685\n"
     ]
    }
   ],
   "source": [
    "no_auto = df[df[\"discrepancia\"] < 0]\n",
    "\n",
    "no_auto_pern = (len(no_auto) / len(df)) * 100\n",
    "\n",
    "print(no_auto_pern)\n",
    "\n",
    "# 69 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7317f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>activation_time_local</th>\n",
       "      <th>country_code</th>\n",
       "      <th>store_address</th>\n",
       "      <th>final_status</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>products</th>\n",
       "      <th>products_total</th>\n",
       "      <th>purchase_total_price</th>\n",
       "      <th>discrepancia</th>\n",
       "      <th>auto_increm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33512615</td>\n",
       "      <td>2019-03-10 23:58:32.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33512451</td>\n",
       "      <td>2019-03-10 23:57:56.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33530892</td>\n",
       "      <td>2019-03-10 23:57:33.000000</td>\n",
       "      <td>ES</td>\n",
       "      <td>19777</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.95</td>\n",
       "      <td>15.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33557765</td>\n",
       "      <td>2019-03-10 23:57:21.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>34565</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>3.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33512273</td>\n",
       "      <td>2019-03-10 23:57:13.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>63536</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>4</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>2.256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id       activation_time_local country_code  store_address  \\\n",
       "0  33512615  2019-03-10 23:58:32.000000           TR          28725   \n",
       "1  33512451  2019-03-10 23:57:56.000000           TR          28725   \n",
       "2  33530892  2019-03-10 23:57:33.000000           ES          19777   \n",
       "3  33557765  2019-03-10 23:57:21.000000           AR          34565   \n",
       "4  33512273  2019-03-10 23:57:13.000000           TR          63536   \n",
       "\n",
       "      final_status payment_status  products  products_total  \\\n",
       "0  DeliveredStatus           PAID         1            3.76   \n",
       "1  DeliveredStatus           PAID         1            2.86   \n",
       "2   CanceledStatus           PAID         1           12.95   \n",
       "3  DeliveredStatus           PAID         2            2.86   \n",
       "4  DeliveredStatus           PAID         4            1.88   \n",
       "\n",
       "   purchase_total_price  discrepancia  auto_increm  \n",
       "0                  3.76          0.00        4.512  \n",
       "1                  2.86          0.00        3.432  \n",
       "2                  0.00         12.95       15.540  \n",
       "3                  6.48         -3.62        3.432  \n",
       "4                  1.96         -0.08        2.256  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"auto_increm\"] = df[\"products_total\"] * 1.2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228d4141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>activation_time_local</th>\n",
       "      <th>country_code</th>\n",
       "      <th>store_address</th>\n",
       "      <th>final_status</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>products</th>\n",
       "      <th>products_total</th>\n",
       "      <th>purchase_total_price</th>\n",
       "      <th>discrepancia</th>\n",
       "      <th>auto_increm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33512615</td>\n",
       "      <td>2019-03-10 23:58:32.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33512451</td>\n",
       "      <td>2019-03-10 23:57:56.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>28725</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33530892</td>\n",
       "      <td>2019-03-10 23:57:33.000000</td>\n",
       "      <td>ES</td>\n",
       "      <td>19777</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.95</td>\n",
       "      <td>15.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33512273</td>\n",
       "      <td>2019-03-10 23:57:13.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>63536</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>4</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>2.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33524023</td>\n",
       "      <td>2019-03-10 23:57:06.000000</td>\n",
       "      <td>EG</td>\n",
       "      <td>73739</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>3</td>\n",
       "      <td>10.19</td>\n",
       "      <td>1.61</td>\n",
       "      <td>8.58</td>\n",
       "      <td>12.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60394</th>\n",
       "      <td>31960607</td>\n",
       "      <td>2019-03-01 00:04:31.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>68820</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>10.17</td>\n",
       "      <td>10.33</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>12.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60395</th>\n",
       "      <td>32002079</td>\n",
       "      <td>2019-03-01 00:03:53.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>50175</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60396</th>\n",
       "      <td>32002046</td>\n",
       "      <td>2019-03-01 00:03:06.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>55159</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.91</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>5.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60397</th>\n",
       "      <td>32001950</td>\n",
       "      <td>2019-03-01 00:01:01.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>62504</td>\n",
       "      <td>CanceledStatus</td>\n",
       "      <td>PAID</td>\n",
       "      <td>1</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60398</th>\n",
       "      <td>32001318</td>\n",
       "      <td>2019-03-01 00:01:00.000000</td>\n",
       "      <td>AR</td>\n",
       "      <td>55159</td>\n",
       "      <td>DeliveredStatus</td>\n",
       "      <td>NOT_PAID</td>\n",
       "      <td>2</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.58</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>6.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_id       activation_time_local country_code  store_address  \\\n",
       "0      33512615  2019-03-10 23:58:32.000000           TR          28725   \n",
       "1      33512451  2019-03-10 23:57:56.000000           TR          28725   \n",
       "2      33530892  2019-03-10 23:57:33.000000           ES          19777   \n",
       "4      33512273  2019-03-10 23:57:13.000000           TR          63536   \n",
       "5      33524023  2019-03-10 23:57:06.000000           EG          73739   \n",
       "...         ...                         ...          ...            ...   \n",
       "60394  31960607  2019-03-01 00:04:31.000000           TR          68820   \n",
       "60395  32002079  2019-03-01 00:03:53.000000           AR          50175   \n",
       "60396  32002046  2019-03-01 00:03:06.000000           AR          55159   \n",
       "60397  32001950  2019-03-01 00:01:01.000000           AR          62504   \n",
       "60398  32001318  2019-03-01 00:01:00.000000           AR          55159   \n",
       "\n",
       "          final_status payment_status  products  products_total  \\\n",
       "0      DeliveredStatus           PAID         1            3.76   \n",
       "1      DeliveredStatus           PAID         1            2.86   \n",
       "2       CanceledStatus           PAID         1           12.95   \n",
       "4      DeliveredStatus           PAID         4            1.88   \n",
       "5      DeliveredStatus           PAID         3           10.19   \n",
       "...                ...            ...       ...             ...   \n",
       "60394  DeliveredStatus           PAID         2           10.17   \n",
       "60395   CanceledStatus           PAID         1            3.80   \n",
       "60396  DeliveredStatus           PAID         1            4.24   \n",
       "60397   CanceledStatus           PAID         1            4.91   \n",
       "60398  DeliveredStatus       NOT_PAID         2            5.14   \n",
       "\n",
       "       purchase_total_price  discrepancia  auto_increm  \n",
       "0                      3.76          0.00        4.512  \n",
       "1                      2.86          0.00        3.432  \n",
       "2                      0.00         12.95       15.540  \n",
       "4                      1.96         -0.08        2.256  \n",
       "5                      1.61          8.58       12.228  \n",
       "...                     ...           ...          ...  \n",
       "60394                 10.33         -0.16       12.204  \n",
       "60395                  0.00          3.80        4.560  \n",
       "60396                  4.91         -0.67        5.088  \n",
       "60397                  0.00          4.91        5.892  \n",
       "60398                  5.58         -0.44        6.168  \n",
       "\n",
       "[41697 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ped_auto_increm = df[df[\"auto_increm\"] >= df[\"purchase_total_price\"]]\n",
    "\n",
    "ped_auto_increm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aaeb6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.03591119058262"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcen_auto_increm = ((len(ped_auto_increm) / len(df)) * 100)\n",
    "\n",
    "\n",
    "porcen_auto_increm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12da4bad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1827\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1829\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03mApply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m    data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountry_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mno_auto\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mporcentaje_no_autorizados\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapply((\u001b[38;5;28mlen\u001b[39m(no_auto) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mporcentaje_no_autorizados\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1846\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1836\u001b[0m             )\n\u001b[0;32m   1837\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1838\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m-> 1846\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "df.groupby(\"country_code\").apply((len(no_auto) / len(df)) * 100).reset_index(name=\"porcentaje_no_autorizados\")\n",
    "\n",
    "print(df.groupby(\"country_code\").apply((len(no_auto) / len(df)) * 100).reset_index(name=\"porcentaje_no_autorizados\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f4788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee1311c",
   "metadata": {},
   "source": [
    "# RECAP\n",
    "\n",
    "## Subconjuntos\n",
    "- Seleccionar columnas específicas:\n",
    "  - `df[[col1, col2]]`\n",
    "\n",
    "## Agreggations\n",
    "### Groupby\n",
    "- Realizar agregaciones basadas en una columna categórica:\n",
    "  - `df[[col1, col2]].groupby(CATEGORICAL).agg({QUANTITATIVE_1: \"mean\", QUANTITATIVE_2: \"max\"})`\n",
    "  - `df[[col1, col2]].groupby(CATEGORICAL).mean()`\n",
    "- Funciones de agregación comunes:\n",
    "  - count (conteo), mean (media), max (máximo), min (mínimo), median (mediana), std (desviación estándar), y más.\n",
    "\n",
    "### Pivot table\n",
    "- Crear tablas pivote para resumir datos:\n",
    "  - `df.pivot_table(values=\"MonthlyIncome\", index=\"Department\", aggfunc=\"mean\")`\n",
    "- Las tablas pivote ofrecen una forma concisa de agregar y comparar datos.\n",
    "\n",
    "### Crosstab\n",
    "- Calcular tabulaciones cruzadas para analizar la relación entre dos variables categóricas:\n",
    "  - El comportamiento predeterminado cuenta ocurrencias.\n",
    "  - Usa `aggfunc=\"mean\"` para agregar variables cuantitativas.\n",
    "  - Asegúrate de seleccionar variables apropiadas.\n",
    "\n",
    "## UNION & MERGE & CONCAT\n",
    "\n",
    "### Concatenación\n",
    "- Combinar DataFrames físicamente (no relacionalmente):\n",
    "  - Lado a lado: `concat` en `axis=1`.\n",
    "    - Usar cuando los DataFrames no comparten columnas o tienen una clave común.\n",
    "  - Arriba & abajo: `concat` en `axis=0` (añadiendo filas).\n",
    "    - Adecuado cuando los DataFrames comparten columnas.\n",
    "\n",
    "### Merge & Join (Pandas)\n",
    "- Merge: Combinar DataFrames basados en columnas comunes.\n",
    "- Join: Combinar DataFrames basados en índices comunes.\n",
    "- En SQL, las operaciones de unión se realizan sobre columnas.\n",
    "\n",
    "Estos puntos de recapitulación resumen operaciones clave para la manipulación y análisis de datos en Pandas. Puedes usar estas técnicas para seleccionar, agregar y combinar datos de manera eficiente, ayudándote a obtener insights de tus conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f340806",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Metodos usuales de pandas\n",
    "```python\n",
    "df.head() # prints the head, default 5 rows\n",
    "df.tail() # set the tail, default 5 rows\n",
    "df.describe() # statistical description\n",
    "df.info() # df information\n",
    "df.columns # show column\n",
    "df.index # show index\n",
    "df.dtypes # show column data types\n",
    "df.plot() # make a plot\n",
    "df.hist() # make a histogram\n",
    "df.col.value_counts() # counts the unique values ​​of a column\n",
    "df.col.unique() # returns unique values ​​from a column\n",
    "df.copy() # copies the df\n",
    "df.drop() # remove columns or rows (axis=0,1)\n",
    "df.dropna() # remove nulls\n",
    "df.fillna() # fills nulls\n",
    "df.shape # dimensions of the df\n",
    "df._get_numeric_data() # select numeric columns\n",
    "df.rename() # rename columns\n",
    "df.str.replace() # replace columns of strings\n",
    "df.astype(dtype='float32') # change the data type\n",
    "df.iloc[] # locate by index\n",
    "df.loc[] # locate by element\n",
    "df.transpose() # transposes the df\n",
    "df.T\n",
    "df.sample(n, frac) # sample from df\n",
    "df.col.sum() # sum of a column\n",
    "df.col.max() # maximum of a column\n",
    "df.col.min() # minimum of one column\n",
    "df[col] # select column\n",
    "df.col\n",
    "df.isnull() # null values\n",
    "df.isna()\n",
    "df.notna() # not null values\n",
    "df.drop_duplicates() # remove duplicates\n",
    "df.reset_index(inplace=True) # reset the index and overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-jefferson",
   "metadata": {},
   "source": [
    "## Más material\n",
    "\n",
    "* [Read the docs!](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* [Cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "* [Exercises to practice](https://github.com/guipsamora/pandas_exercises)\n",
    "* [More on merge, concat, and join](https://realpython.com/pandas-merge-join-and-concat/#pandas-join-combining-data-on-a-column-or-index). And [even more!](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.766px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
