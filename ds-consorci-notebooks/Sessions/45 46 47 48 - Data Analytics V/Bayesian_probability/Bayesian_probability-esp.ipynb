{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWzt_ckQEAFH"
   },
   "source": [
    "# Estadísticas Bayesianas\n",
    "\n",
    "> Las estadísticas Bayesianas son una teoría en el campo de la estadística basada en la **interpretación Bayesiana de la probabilidad** donde la probabilidad expresa un grado de creencia en un evento.\n",
    "> El grado de creencia puede basarse en conocimientos previos sobre el evento, como los resultados de experimentos anteriores, o en creencias personales sobre el evento.\n",
    "> Esto difiere de una serie de otras interpretaciones de la probabilidad, como la interpretación frecuentista que ve la probabilidad como el límite de la frecuencia relativa de un evento después de muchos ensayos.\n",
    "\n",
    ">(Fuente: *Wikipedia*)\n",
    "\n",
    "## La \"fórmula\" de Bayes\n",
    "\n",
    "El teorema de Bayes es un teorema fundamental en las estadísticas Bayesianas.\n",
    "\n",
    "$$ P(H | E) = \\frac{P(E | H)P(H)}{P(E)}$$\n",
    "\n",
    "La fórmula de Bayes se puede usar en estadísticas frecuentistas para calcular **probabilidades condicionales**, pero en estadísticas Bayesianas se usa para calcular **probabilidades posteriores** (en oposición a **probabilidades previas**), dadas las observaciones.\n",
    "\n",
    "> Por ejemplo, se observa que un paciente tiene un cierto síntoma ($E$), y la fórmula de Bayes se puede usar para calcular la probabilidad de que un diagnóstico ($H$) sea correcto, dada esa observación.\n",
    "\n",
    "Las estadísticas Bayesianas **interpretan las probabilidades como medidas de credibilidad** (qué tan confiados estamos) en un evento, **no como la frecuencia a largo plazo de los eventos**.\n",
    "\n",
    "Las medidas de creencias se aplican a individuos, no a la naturaleza, por lo que hay espacio para creencias conflictivas entre individuos. Las diferentes creencias no se interpretan como errores, sino como **diferentes estados de conocimiento sobre un evento**.\n",
    "\n",
    "La fórmula se interpreta como una **actualización de la creencia después de observar datos**.\n",
    "\n",
    "### Una nota sobre la subjetividad Bayesiana\n",
    "\n",
    "> Los métodos Bayesianos a menudo se caracterizan como “subjetivos” porque el usuario debe elegir una distribución previa, es decir, una expresión matemática de la información previa.\n",
    "\n",
    "> La distribución previa requiere información y entrada del usuario, eso es seguro, pero no veo esto como algo más “subjetivo” que otros aspectos de un procedimiento estadístico, como la elección del modelo para los datos (por ejemplo, regresión logística) o la elección de qué variables incluir en una predicción, la elección de qué coeficientes deberían variar con el tiempo o entre situaciones, la elección de la prueba estadística, y así sucesivamente.\n",
    "\n",
    "> De hecho, los métodos Bayesianos pueden de muchas maneras ser más “objetivos” que los enfoques convencionales en que la inferencia Bayesiana, con su suavizado y agrupación parcial, está bien adaptada para incluir diversas fuentes de información y así puede reducir el número de puntos de decisión de codificación de datos o exclusión de datos.\n",
    "\n",
    "> *Andrew Gelman, Profesor de estadísticas y ciencia política y director del Centro de Estadísticas Aplicadas en la Universidad de Columbia*.\n",
    "\n",
    "# Análisis de Datos Bayesianos\n",
    "\n",
    "Imaginemos ahora el siguiente escenario: Queremos saber la *probabilidad* de que el último filme en el que un actor ha protagonizado gane un Oscar.\n",
    "\n",
    "En este caso, la noción *frecuentista* de **serie de ensayos** no está bien definida: cada año la situación es diferente, no hay series de ensayos idénticos a considerar. Podemos concluir que la noción clásica de probabilidad no se aplica a estas situaciones.\n",
    "\n",
    "Pero el **Bayesianismo** define la probabilidad de una manera diferente: **el grado de creencia de que un evento ocurrirá**.\n",
    "\n",
    "¿Cuál es la probabilidad de que Bin Laden esté muerto? Para un frecuentista no hay probabilidad para este evento porque no hay ensayos posibles (Bin Laden está muerto o no lo está, no es una cuestión de probabilidad). Un Bayesianista asignaría una probabilidad a este evento basado en su **estado de conocimiento**. El estado de conocimiento cambia cuando hay nueva información disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BF5Mz81EAFM"
   },
   "source": [
    "## La regla de Bayes\n",
    "\n",
    "La principal herramienta del Análisis Bayesiano es el teorema de Bayes, presentado en 1763:\n",
    "\n",
    "<b> Teorema de Bayes </b> <br>\n",
    "$$ P(A | B) = \\frac{P(B | A)P(A)}{P(B)}$$\n",
    "</div>   \n",
    "\n",
    "Este teorema describe la relación entre las probabilidades condicionales de dos eventos.\n",
    "\n",
    "Es fácil demostrar que esto es cierto. Son solo aritmética básica basada en reglas de probabilidad (regla de la cadena):\n",
    "\n",
    "+ Sabemos que $ P(A \\mbox{ y } B) = P(A)P(B | A) $.\n",
    "+ Pero también es cierto que $ P(A \\mbox{ y } B) = P(B)P(A | B)$.\n",
    "+ Entonces, $ P(A)P(B | A) = P(B)P(A | B)$. \n",
    "\n",
    "Aunque esto se llama teorema de Bayes, la **forma general** de este como se enuncia aquí fue en realidad escrita por primera vez no por Thomas Bayes, sino por Pierre-Simon Laplace. Lo que Bayes hizo fue derivar el caso especial de esta fórmula para \"invertir\" la distribución binomial.\n",
    "\n",
    "### Hipótesis y evidencias.\n",
    "\n",
    "La interpretación más común del Teorema de Bayes se basa en considerar que $A$ es una hipótesis $H$ y $B$ una nueva evidencia $E$ que debería modificar nuestra creencia en $H$:\n",
    "\n",
    "$$P(H | E) = P(H) \\frac{P(E|H)}{P(E)}$$\n",
    "\n",
    "Esto se llama la **interpretación diacrónica** porque describe cómo *una hipótesis debe actualizarse con el tiempo cada vez que se encuentra una nueva evidencia*.\n",
    "\n",
    "\n",
    "+ $P(H | E)$ se llama el **posterior**.\n",
    "+ $P(H)$ se llama la **probabilidad previa** de la hipótesis.\n",
    "+ $P(E | H)$ se llama la **verosimilitud** de la evidencia.\n",
    "+ $P(E)$ es una constante de normalización. Si hay $n$ hipótesis que son *mutuamente excluyentes* y *exhaustivamente colectivas*, podemos calcular $P(E)$ como:\n",
    "\n",
    "$$ P(E) = P(H_1)P(E|H_1) + \\dots + P(H_n)P(E|H_n)$$\n",
    "\n",
    "\n",
    "En general, $P(H | E), P(H), P(E|H), P(E)$ son funciones! \n",
    "\n",
    "Podemos extraer estimaciones puntuales, estimaciones de conjunto y proposiciones probabilísticas de $P(H | E)$.\n",
    "\n",
    "### Ejemplo: Visualización de la regla de Bayes<br>\n",
    "\n",
    "Supongamos que estamos viviendo una pandemia. Diga que $P(H_{yes})=5\\%$ es la **prevalencia** de la enfermedad y que  \n",
    "cada individuo de la población recibe una prueba con una precisión de $P(E_{yes}|H_{yes})=P(E_{no}|H_{no}) = 90\\%$.  \n",
    "\n",
    "Queremos saber la **probabilidad de tener la enfermedad si ha dado positivo**: \n",
    "$$Pr(H_{yes}|E_{yes})$$. \n",
    "\n",
    "Podemos usar la regla de Bayes para calcular este posterior:\n",
    "\n",
    "$$ P(H_{yes}|E_{yes}) = \\frac{P(H_{yes}) P(E_{yes}|H_{yes}) }{P(E_{yes})} = $$\n",
    "\n",
    "$$ = \\frac{P(H_{yes})P(E_{yes}|H_{yes}) }{P(H_{yes})P(E_{yes}|H_{yes}) + P(H_{no})P(E_{yes}|H_{no})} $$\n",
    "\n",
    "Eso es\n",
    "\n",
    "$$ = \\frac{0.05 \\times 0.9}{0.05 \\times 0.9 + 0.95 \\times 0.1} \\approx 0.32 $$\n",
    "\n",
    "Muchos encuentran contraintuitivo que esta probabilidad sea mucho menor que el $90\\%$; este gif animado está destinado a ayudar.\n",
    "\n",
    "El `O` en el medio se convierte en una `X` cuando la prueba falla. La tasa de `X`s es $1-Pr(E_{yes}|H_{yes})$. \n",
    "\n",
    "![ChessUrl](https://raw.githubusercontent.com/simplystats/simplystats.github.io/master/_images/bayes.gif \"chess\")\n",
    "\n",
    "### Ejemplo: Problema de Monty Hall\n",
    "\n",
    "> \"*Let's Make a Deal*\" es un programa de juegos de televisión que se originó en los Estados Unidos y desde entonces se ha producido en muchos países del mundo. El programa se basa en ofertas hechas a los miembros del público por el anfitrión. Los comerciantes generalmente tienen que sopesar la posibilidad de una oferta por premios valiosos, o artículos indeseables, denominados \"Zonks\".\n",
    "\n",
    ">*Fuente: Wikipedia*.\n",
    "\n",
    "Monty Hall fue el presentador original del juego. El problema de Monty Hall se basa en uno de los juegos regulares del programa. Es un problema de pegar o cambiar:\n",
    "+ Supongamos que estás en el programa de juegos y te dan a elegir entre tres puertas: Detrás de una puerta hay un coche; detrás de los otros, cabras.\n",
    "+ Eliges una puerta, digamos la Puerta A (la puerta no se abre), y el presentador, que sabe qué hay detrás de las puertas, abre la Puerta B, que tiene una cabra.\n",
    "+ Luego te dice: \"¿Quieres elegir la Puerta C?\" ¿Te conviene cambiar tu elección?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebq8cShfPk0H"
   },
   "source": [
    "<img src=\"./images/lets.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv0Lp36oQHxY"
   },
   "source": [
    "<img src=\"./images/monty.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAoXa7TPEAFO"
   },
   "source": [
    "La mayoría de la gente piensa intuitivamente que no hace ninguna diferencia si se cambia de elección o no, ¡pero esto es incorrecto!\n",
    "\n",
    "La verdad es que si te quedas con tu elección original, la probabilidad de ganar es de 1/3; si cambias, tus probabilidades son de 2/3.\n",
    "\n",
    "Podemos usar el punto de vista Bayesiano para resolver este problema. Al principio, hay diferentes hipótesis $H$ con sus correspondientes probabilidades **previas**:\n",
    "\n",
    "+ A: el coche está detrás de la Puerta A; $P(H=\\mbox{'A'}) = 1/3$\n",
    "+ B: el coche está detrás de la Puerta B; $P(H=\\mbox{'B'}) = 1/3$\n",
    "+ C: el coche está detrás de la Puerta C; $P(H=\\mbox{'C'}) = 1/3$\n",
    "\n",
    "Eliges A al azar. Si te quedas con A después de que Monty abre la puerta B (esta es nuestra evidencia *E*). Podemos calcular $P(H=\\mbox{'A'}|E)$:\n",
    "\n",
    "$$ P(H=\\mbox{'A'}|E) = \\frac{P(H=\\mbox{'A'})P(E|H=\\mbox{'A'})}{P(E)} $$\n",
    "$$= \\frac{1/3 \\times 1/2}{1/3 \\times 1/2 + 1/3 \\times 0 + 1/3 \\times 1} = 1/3$$ \n",
    "\n",
    "El denominador se puede entender de esta manera: Estamos asumiendo que inicialmente elegimos A. Sigue que si el coche está detrás de A, Monty nos mostrará una cabra detrás de B la mitad del tiempo. Si el coche está detrás de B, Monty nunca nos mostrará una cabra detrás de B. Finalmente, si el coche está detrás de C, Monty nos mostrará una cabra detrás de B cada vez.\n",
    "\n",
    "**¿Cuál es la probabilidad si cambiamos de elección?**\n",
    "\n",
    "Para conocer $P(H=\\mbox{'C'}|E)$ también podrías aplicar el Teorema de Bayes directamente, pero hay una forma más sencilla de calcularlo: Dado que la probabilidad de que esté detrás de A es de 1/3 y la suma de las dos probabilidades debe ser igual a 1, la probabilidad de que el coche esté detrás de C es 1−1/3=2/3. \n",
    "\n",
    "\n",
    "Samuel Arbesman, Wired, 11.26.14: \n",
    "\n",
    "> De hecho, Paul Erdős, uno de los matemáticos más prolíficos y destacados involucrados en probabilidad, cuando se le presentó inicialmente el problema de Monty Hall también cayó en la trampa de no entender por qué abrir una puerta debería hacer alguna diferencia. Incluso después de recibir la explicación matemática varias veces, no estaba realmente convencido. Le tomó varios días antes de que finalmente entendiera la solución correcta.\n",
    "\n",
    "Hagamos una **simulación** del juego para calcular $P(H=\\mbox{'C'}|E)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9ePwTNPEAFO",
    "outputId": "e2014d4e-cd79-4f3e-f83e-55036d93682f"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "iterations = 100000\n",
    "doors = [\"goat\"] * 2 + [\"car\"]\n",
    "change_wins = 0\n",
    "change_loses = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    random.shuffle(doors)\n",
    "    \n",
    "    # you pick door n:\n",
    "    n = random.randrange(3)\n",
    "    \n",
    "    # monty picks door k, k!=n and doors[k]!=\"car\"\n",
    "    sequence = list(range(3))\n",
    "    random.shuffle(sequence)\n",
    "    for k in sequence:\n",
    "        if k == n or doors[k] == \"car\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # now if you change, you lose iff doors[n]==\"car\"\n",
    "    if doors[n] == \"car\":\n",
    "        change_loses += 1\n",
    "    else:\n",
    "        change_wins += 1\n",
    "\n",
    "perc = (100.0 * change_wins) / (change_wins + change_loses)\n",
    "print(\"Switching has %s wins and %s losses: you win %.1f%% of the time\" % (change_wins, change_loses, perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak2GyEGiEAFO"
   },
   "source": [
    "### Ejercicio: Regla de Bayes\n",
    "\n",
    "Calcula \\( P(H='C'|E) \\) aplicando la Regla de Bayes y verifica el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L95Ax2P7EAFP",
    "outputId": "d0930360-906c-49a1-cd68-50003fab16e2"
   },
   "outputs": [],
   "source": [
    "# your solution here\n",
    "\n",
    "P = 0\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj7UeDLfEAFP"
   },
   "source": [
    "### Ejercicio: Prueba Clínica\n",
    "\n",
    "**¿Cuál es la evidencia de una enfermedad después de una prueba clínica?**\n",
    "\n",
    "Datos:\n",
    "\n",
    "+ El 1% de las mujeres de cuarenta años que participan en cribados rutinarios tienen cáncer de mama.\n",
    "+ El 80% de las mujeres con cáncer de mama obtendrán mamografías positivas.\n",
    "+ El 9.6% de las mujeres sin cáncer de mama también obtendrán mamografías positivas.\n",
    "\n",
    "Una mujer de este grupo de edad obtuvo una mamografía positiva en un cribado rutinario.\n",
    "\n",
    "- **¿Cuál es la probabilidad de que realmente tenga cáncer de mama?**\n",
    "\n",
    "- **¿Es esta una \"buena\" prueba para detectar cáncer de mama?**\n",
    "\n",
    "Para responder a estas preguntas, aplicamos la Regla de Bayes y consideramos lo siguiente:\n",
    "\n",
    "+ \\( P(\\text{cáncer}) = 0.01 \\) y \\( P(\\text{sin cáncer}) = 0.99 \\).\n",
    "+ Si obtienes \\( + \\), entonces \\( P(+ | \\text{cáncer}) = 0.8 \\) y \\( P(+ | \\text{sin cáncer}) = 0.096 \\).\n",
    "\n",
    "Primero calculamos \\( P(+) \\), la probabilidad total de obtener un resultado positivo, utilizando la ley total de la probabilidad:\n",
    "\n",
    "$$ P(+) = P(\\text{cáncer}) \\cdot P(+ | \\text{cáncer}) + P(\\text{sin cáncer}) \\cdot P(+ | \\text{sin cáncer}) $$\n",
    "$$ P(+) = (0.01 \\cdot 0.8) + (0.99 \\cdot 0.096) $$\n",
    "$$ P(+) = 0.008 + 0.09504 = 0.10304 $$\n",
    "\n",
    "Aplicamos la Regla de Bayes para calcular \\( P(\\text{cáncer} | +) \\):\n",
    "\n",
    "$$ P(\\text{cáncer} | +) = \\frac{P(\\text{cáncer}) \\cdot P(+ | \\text{cáncer})}{P(+)} $$\n",
    "$$ P(\\text{cáncer} | +) = \\frac{0.01 \\cdot 0.8}{0.10304} $$\n",
    "$$ P(\\text{cáncer} | +) \\approx 0.0776 $$\n",
    "\n",
    "**Respuesta a la primera pregunta:**\n",
    "\n",
    "La probabilidad de que realmente tenga cáncer de mama después de obtener un resultado positivo es aproximadamente del 7.76%.\n",
    "\n",
    "**Respuesta a la segunda pregunta:**\n",
    "\n",
    "Para determinar si esta es una \"buena\" prueba, observamos la probabilidad de que no tenga cáncer a pesar de un resultado positivo, \\( P(\\text{sin cáncer} | +) \\):\n",
    "\n",
    "$$ P(\\text{sin cáncer} | +) = \\frac{P(\\text{sin cáncer}) \\cdot P(+ | \\text{sin cáncer})}{P(+)} $$\n",
    "$$ P(\\text{sin cáncer} | +) = \\frac{0.99 \\cdot 0.096}{0.10304} $$\n",
    "$$ P(\\text{sin cáncer} | +) \\approx 0.922 $$\n",
    "\n",
    "A pesar de un resultado positivo, hay aproximadamente un 92.2% de probabilidad de no tener cáncer, lo que indica que la prueba produce un alto número de falsos positivos. Por lo tanto, esta no sería considerada una \"buena\" prueba para detectar cáncer de mama de manera eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvjgbhk3EAFP"
   },
   "outputs": [],
   "source": [
    "# Your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B6kTVQUEAFP"
   },
   "source": [
    "### Ejercicio: Segunda prueba clínica\n",
    "\n",
    "Supongamos que el resultado de una segunda prueba para una mujer determinada *es independiente* del primero (esto claramente es una suposición incorrecta en el mundo real, ¡pero vamos a suponer que es cierto!). **¿Cuál es la probabilidad de tener cáncer después de un resultado positivo en una segunda prueba?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVQFNI_DEAFQ",
    "outputId": "b40259f6-bbff-4863-eba4-6aff49b22d58"
   },
   "outputs": [],
   "source": [
    "# Your solution here.\n",
    "\n",
    "P2 = 0\n",
    "print(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0-NXiANEAFQ"
   },
   "source": [
    "## El problema de la locomotora.\n",
    "\n",
    "Una compañía ferroviaria numera sus locomotoras en orden de $1 \\dots N$. Un día ves una locomotora con el número 60. Estima cuántas locomotoras tiene la compañía ferroviaria.\n",
    "\n",
    "> Durante la Segunda Guerra Mundial, la *División de Guerra Económica* de la Embajada Americana en Londres utilizó análisis estadístico para estimar la producción alemana de tanques y otros equipos.\n",
    "Los Aliados Occidentales habían capturado libros de registro, inventarios y registros de reparaciones que incluían números de serie de chasis y motores para tanques individuales.\n",
    "\n",
    "> El análisis de estos registros indicó que los números de serie se asignaban por fabricante y tipo de tanque en bloques de 100 números, que los números en cada bloque se usaban secuencialmente, y que no todos los números en cada bloque se utilizaban. Así que el problema de estimar la producción de tanques alemanes podría reducirse, dentro de cada bloque de 100 números, a una forma del problema de la locomotora.\n",
    "\n",
    "> Basado en esta perspectiva, analistas estadounidenses y británicos produjeron estimaciones sustancialmente más bajas que las estimaciones de otras formas de inteligencia. Y después de la guerra, los registros indicaron que eran sustancialmente más precisos.\n",
    "\n",
    "> *(Fuente: http://greenteapress.com/thinkbayes/html/thinkbayes004.html#toc24)*\n",
    "\n",
    "Basado en la observación, sabemos que el ferrocarril tiene 60 o más locomotoras. ¿Pero cuántas más?\n",
    "\n",
    "Para aplicar el razonamiento Bayesiano, podemos dividir este problema en dos pasos:\n",
    "\n",
    "+ ¿Qué sabíamos sobre $N$ antes de ver los datos?\n",
    "+ Para cualquier valor dado de $N$, ¿cuál es la probabilidad de ver los datos (una locomotora con número 60)?\n",
    "\n",
    "La respuesta a la primera pregunta es el **prior**, $P(H)$. La respuesta a la segunda es la **verosimilitud**, $P(E|H)$.\n",
    "\n",
    "No tenemos mucha base para elegir un prior, pero podemos comenzar con algo simple y luego considerar alternativas. Supongamos que $N$ puede ser cualquier valor de 1 a 1000 con un prior plano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "feiJqEpeEAFQ",
    "outputId": "3e7d2d6f-3f17-4a82-e785-bea666805611"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hypos = np.array(range(1, 1001))\n",
    "priors = np.array([1.0/len(hypos) for hypo in hypos])\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(hypos, priors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-ZwE0w8EAFQ"
   },
   "source": [
    "Ahora todo lo que necesitamos es una **función de verosimilitud**, $P(E|H)$.\n",
    "\n",
    "En una flota hipotética de $N$ locomotoras, ¿cuál es la probabilidad de que viéramos el número 60?\n",
    "\n",
    "Si asumimos que hay solo una compañía de trenes operando (o solo una que nos interesa) y que tenemos la misma probabilidad de ver cualquiera de sus locomotoras, entonces la posibilidad de ver una locomotora particular es $1/N$ y que hay al menos $N$ locomotoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my86tvinEAFQ"
   },
   "outputs": [],
   "source": [
    "def Likelihood(data, hypo):\n",
    "    if hypo < data:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0/hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPoptm3sEAFQ"
   },
   "source": [
    "Vamos a incorporar nuestros datos en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "MjzmS2baEAFQ",
    "outputId": "47e74c95-e521-4be2-e9c8-1d25e1728300"
   },
   "outputs": [],
   "source": [
    "def Posterior(data, hypos, priors):\n",
    "    import numpy as np\n",
    "    posterior = np.array([Likelihood(data, hypo) for hypo in hypos]) * priors\n",
    "    return posterior\n",
    "\n",
    "# After an update, the distribution is no longer normalized, \n",
    "# but because these hypotheses are mutually exclusive and \n",
    "# collectively exhaustive, we can renormalize.\n",
    "\n",
    "def Normalize(d):\n",
    "    total = d.sum()\n",
    "    factor = 1.0 / total\n",
    "    for i in range(len(d)):\n",
    "        d[i] *= factor\n",
    "    return d\n",
    "\n",
    "posterior = Normalize(Posterior(60, hypos, priors))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.ylim([-0.001,0.006])\n",
    "    plt.plot(hypos, posterior)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTq021-nEAFQ"
   },
   "source": [
    "El valor más probable, si tuvieras que adivinar, es 60. Eso podría no parecer una muy buena suposición; después de todo, ¿cuáles son las probabilidades de que justo hayas visto el tren con el número más alto?\n",
    "\n",
    "Sin embargo, si quieres maximizar la posibilidad de acertar exactamente, deberías adivinar 60.\n",
    "\n",
    "Pero quizás ese no sea el objetivo correcto. Una alternativa es calcular la estimación de Bayes, la **hipótesis que corresponde al valor medio de la distribución posterior**:\n",
    "\n",
    "$\\hat H (E) = \\mathbb{E}[H | E] = \\int H p(H | E) dH$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2raCGdR4EAFQ",
    "outputId": "7415eff3-3d13-4cf9-bf08-c4dfaa76d069"
   },
   "outputs": [],
   "source": [
    "def Meanp(hypos, posterior):\n",
    "    total = 0.0\n",
    "    s = hypos * posterior\n",
    "    return s.mean()*len(hypos)\n",
    "\n",
    "print(int(Meanp(hypos, posterior)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pc-gdaLHEAFR"
   },
   "source": [
    "Si queremos aumentar nuestro conocimiento, hay dos maneras de proceder:\n",
    "\n",
    "+ Obtener más datos.\n",
    "+ Obtener más información de fondo.\n",
    "\n",
    "Por ejemplo, supongamos que además del tren 60 también vemos los trenes 30 y 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "G2Iox1ibEAFR",
    "outputId": "ee94a426-4232-46b0-ac9a-cfe8988f5d25"
   },
   "outputs": [],
   "source": [
    "hypos = range(1, 1001)\n",
    "posterior =  Normalize(Posterior(60, hypos, priors))\n",
    "posterior2 = Normalize(Posterior(30, hypos, posterior))\n",
    "posterior3 = Normalize(Posterior(90, hypos, posterior2))\n",
    "\n",
    "print(int(Meanp(hypos, posterior3)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.ylim([-0.001,0.025])\n",
    "    plt.plot(hypos, posterior3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MS9ZoA5aEAFR"
   },
   "source": [
    "Podemos refactorizar nuestras funciones de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "2bNzq1fgEAFR",
    "outputId": "109c3330-6a18-49f7-8df7-faa83517f0ed"
   },
   "outputs": [],
   "source": [
    "def Normalize(d):\n",
    "    total = d.sum()\n",
    "    factor = 1.0 / total\n",
    "    for i in range(len(d)):\n",
    "        d[i] *= factor\n",
    "    return d\n",
    "\n",
    "def Likelihood1(datum, hypo):\n",
    "    if hypo < datum:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0/hypo\n",
    "    \n",
    "def Posterior(datum, hypos, priors, likelihood):\n",
    "    import numpy as np\n",
    "    posterior = np.array([likelihood(datum, hypo) for hypo in hypos]) * priors\n",
    "    return posterior\n",
    "\n",
    "def Posterior_n(data, hypos, priors, likelihood):\n",
    "    p = priors\n",
    "    for d in data:\n",
    "        posterior =  Normalize(Posterior(d, hypos, p, likelihood))\n",
    "        p = posterior\n",
    "    return posterior\n",
    "\n",
    "def Meanp(hypos, posterior):\n",
    "    total = 0.0\n",
    "    s = hypos * posterior\n",
    "    return s.mean()*len(hypos)\n",
    "\n",
    "hypos = np.array(range(1, 1001))\n",
    "priors = np.array([1.0/len(hypos) for hypo in hypos])\n",
    "posteriors = Posterior_n([60,30,90], hypos, priors, Likelihood1)\n",
    "\n",
    "print('Mean of the posterior distribution with 1000 hypotheses: ', \\\n",
    "        int(Meanp(hypos, posteriors)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.ylim([-0.001,0.025])\n",
    "    plt.plot(hypos, posteriors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY2y505EEAFR"
   },
   "source": [
    "Con más datos, **las distribuciones posteriores basadas en diferentes priores tienden a converger**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGAABkKKEAFR",
    "outputId": "09553c1c-ff0b-418d-8083-1cfe26385b86"
   },
   "outputs": [],
   "source": [
    "hypos = np.array(range(1, 501))\n",
    "priors = np.array([1.0/len(hypos) for hypo in hypos])\n",
    "posteriors = Posterior_n([60,60,90], hypos, priors, Likelihood1)\n",
    "print('Mean of the posterior distribution with 500 hypotheses: ', \n",
    "      int(Meanp(hypos, posteriors)))\n",
    "\n",
    "hypos = np.array(range(1, 2001))\n",
    "priors = np.array([1.0/len(hypos) for hypo in hypos])\n",
    "posteriors = Posterior_n([60,60,90], hypos, priors, Likelihood1)\n",
    "print('Mean of the posterior distribution with 2000 hypotheses: ', \n",
    "      int(Meanp(hypos, posteriors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWg2r8A_EAFR"
   },
   "source": [
    "Si no están disponibles más datos, otra opción es mejorar los priores recopilando más información de fondo. Probablemente no sea razonable suponer que una compañía que opera trenes con 1000 locomotoras es tan probable como una compañía con solo 1.\n",
    "\n",
    "Supongamos que la distribución del número total de locomotoras de una compañía tiende a seguir una **ley de potencia**.\n",
    "\n",
    "Esta ley sugiere que si hay 1000 compañías con menos de 10 locomotoras, podría haber 100 compañías con 100 locomotoras, 10 compañías con 1000, y posiblemente una compañía con 10,000 locomotoras.\n",
    "\n",
    "Matemáticamente, una ley de potencia significa que el número de compañías con un tamaño dado es inversamente proporcional al tamaño:\n",
    "\n",
    "$$ f(x) = \\left( \\frac{1}{x} \\right)^\\alpha $$\n",
    "\n",
    "donde $f(x)$ es la función de masa de probabilidad de $x$ y $\\alpha$ es un parámetro (que a menudo está cerca de 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "Pn-ZcRWCEAFR",
    "outputId": "0971c1fd-80f5-4958-fa37-a3154609e3b8"
   },
   "outputs": [],
   "source": [
    "def Likelihood2(data, hypo, alpha=1.0):\n",
    "    if hypo < data:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return hypo**(-alpha)\n",
    "\n",
    "alpha = 1.0\n",
    "hypos = np.array(range(1, 1001))\n",
    "priors = Normalize(np.array([Likelihood2(0, hypo, alpha) for hypo in hypos]))\n",
    "\n",
    "print(int(Meanp(hypos, priors)))\n",
    "    \n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.ylim([-0.01,0.14])\n",
    "    plt.xlim([-10,500])\n",
    "    plt.plot(hypos, priors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "7JuaDX8eEAFR",
    "outputId": "0ca2f90c-e846-4217-d5f2-9ebbf7d12879"
   },
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "\n",
    "hypos = np.array(range(1, 1001))\n",
    "priors = Normalize(np.array([Likelihood2(0, hypo, alpha) for hypo in hypos]))\n",
    "\n",
    "posteriors = Posterior_n([30,60,90], hypos, priors, Likelihood2)\n",
    "\n",
    "print('Mean of the posterior distribution with 1000 hypotheses: ', int(Meanp(hypos, posteriors)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.ylim([-0.001,0.035])\n",
    "    plt.plot(hypos, posteriors)\n",
    "    plt.axvline(x=int(Meanp(hypos, posteriors)), ymin=0.0, ymax = 0.9, \\\n",
    "                linewidth=1, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "ra2d51xEEAFR",
    "outputId": "1e0a66bc-24f4-4ae3-8534-b865fa1568a7"
   },
   "outputs": [],
   "source": [
    "hypos = np.array(range(1, 501))\n",
    "priors = Normalize(np.array([Likelihood2(0, hypo, alpha) for hypo in hypos]))\n",
    "\n",
    "posteriors = Posterior_n([30,60,90], hypos, priors, Likelihood2)\n",
    "\n",
    "print('Mean of the posterior distribution with 500 hypotheses: ',int(Meanp(hypos, posteriors)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.ylim([-0.001,0.035])\n",
    "    plt.xlim([0,2000])\n",
    "    plt.plot(hypos, posteriors)\n",
    "    plt.axvline(x=int(Meanp(hypos, posteriors)), ymin=0.0, ymax = 0.9, \\\n",
    "                linewidth=1, color='r')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "hypos = np.array(range(1, 2001))\n",
    "priors = Normalize(np.array([Likelihood2(0, hypo, alpha) for hypo in hypos]))\n",
    "\n",
    "posteriors = Posterior_n([30,60,90], hypos, priors, Likelihood2)\n",
    "\n",
    "print('Mean of the posterior distribution with 2000 hypotheses: ',int(Meanp(hypos, posteriors)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.ylim([-0.001,0.035])\n",
    "    plt.plot(hypos, posteriors)\n",
    "    plt.axvline(x=int(Meanp(hypos, posteriors)), ymin=0.0, ymax = 0.9, \\\n",
    "                linewidth=1, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J571-GltEAFS"
   },
   "source": [
    "### MAP e intervalos creíbles\n",
    "\n",
    "Una vez que tenemos la **distribución posterior**, podríamos estar interesados en resumir el resultado con una **estimación puntual** o un **intervalo creíble**.\n",
    "\n",
    "Para las estimaciones puntuales podemos usar la media, la mediana o el **modo**. Esta última estimación se llama **estimación máxima a posteriori (MAP)**.\n",
    "\n",
    "Para los intervalos, generalmente informamos dos valores calculados de modo que exista un 95% de probabilidad de que el valor desconocido caiga entre ellos (o cualquier otra probabilidad). Estos valores definen un **intervalo creíble**.\n",
    "\n",
    "Una forma simple de calcular el intervalo creíble del 95% es sumar las probabilidades en la distribución posterior y registrar los valores que corresponden a las probabilidades del 2.5% y el 97.5%. En otras palabras, los percentiles 2.5 y 97.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "mUqUEYW3EAFS",
    "outputId": "3da69352-b1ad-4ee3-ac6c-bd56e569e24e"
   },
   "outputs": [],
   "source": [
    "def Percentile(hypos, posterior, percentage):\n",
    "    import numpy as np\n",
    "    p = percentage / 100.0\n",
    "    cdf = np.cumsum(np.array(posterior))\n",
    "    total = 0\n",
    "    for i in range(len(hypos)):\n",
    "        total += posterior[i]\n",
    "        if total >= p:\n",
    "            return hypos[i] \n",
    "\n",
    "alpha = 1.0\n",
    "\n",
    "hypos = np.array(range(1, 1001))\n",
    "priors = Normalize(np.array([Likelihood2(0, hypo, alpha) for hypo in hypos]))\n",
    "posteriors = Posterior_n([30,60,90], hypos, priors, Likelihood2)      \n",
    "\n",
    "print('The credible interval is [', Percentile(hypos, posteriors, 2.5),',', \\\n",
    "            Percentile(hypos, posteriors, 97.5), ']')\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig = plt.figure(figsize=(10,2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.ylim([-0.001,0.035])\n",
    "    plt.plot(hypos, posteriors)\n",
    "    plt.axvspan(Percentile(hypos, posteriors, 2.5), Percentile(hypos, posteriors, 97.5), facecolor='0.5', alpha=0.2)\n",
    "    plt.axvline(x=int(Meanp(hypos, posteriors)), ymin=0.0, ymax = 1, \\\n",
    "                linewidth=1, color='r')\n",
    "    ax.set_xlabel('The credible interval is [ 90 , 303 ]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WSpzzi7EAFS"
   },
   "source": [
    "Para el ejemplo anterior—el problema de la locomotora con un prior de ley de potencia y tres trenes—el intervalo creíble del 90% es (90, 303). La amplitud de este rango sugiere, correctamente, que aún estamos bastante inciertos sobre cuántas locomotoras hay.\n",
    "\n",
    "## Comparación de hipótesis Bayesianas.\n",
    "\n",
    "Desde un punto de vista frecuentista, decimos que un efecto $H_A$ es estadísticamente significativo (o no) calculando las probabilidades (verosimilitud) del efecto bajo una hipótesis nula $P(E|H_0)$, pero no puedes concluir que es real.\n",
    "\n",
    "Desde un punto de vista Bayesiano, lo que calculamos directamente es $P(H_A | E)$, donde $H_A$ es la hipótesis de que el efecto es real.\n",
    "\n",
    "Por el Teorema de Bayes:\n",
    "\n",
    "$$ P(H_A | E) = \\frac{P(E|H_A) P(H_A)}{P(E)} = \\frac{P(E|H_A) P(H_A)}{P(E | H_A)P(H_A) + P(E | H_0)P(H_0)} $$\n",
    "\n",
    "Para calcular $P(E | H_A)$, el término de verosimilitud, podemos seguir un enfoque similar al empleado para calcular $P(E | H_0)$, generando 1000 pares de muestras, uno de cada distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGlAzS2ZEAFS",
    "outputId": "b41df86b-48f4-4fbe-87da-4342898e8dba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "file = open('2002FemPreg.dat', 'r')\n",
    "seed = 41\n",
    "np.random.seed(seed)\n",
    "\n",
    "def chr_int(a):\n",
    "    if a == '  ':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(a)\n",
    "        \n",
    "preg=[]\n",
    "for line in file:\n",
    "    lst  = [int(line[:12]), int(line[274:276]), int(line[276]), \\\n",
    "                 chr_int(line[277:279]), float(line[422:440])]\n",
    "    preg.append(lst)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(preg)\n",
    "df.columns = ['caseid', 'prglength', 'outcome', 'birthord', 'finalwgt']\n",
    "\n",
    "#data cleaning\n",
    "df2 = df.drop(df.index[(df.outcome == 1) & (df['prglength'] > df['prglength'].median() + 6)])\n",
    "df2[(df2.outcome == 1) & \n",
    "    (df2['prglength'] > df2['prglength'].median() + 6)]\n",
    "df3 = df2.drop(df2.index[(df2.outcome == 1) &\n",
    "                         (df2['prglength'] < df2['prglength'].median() -10)])\n",
    "df3[(df3.outcome == 1) & \n",
    "    (df3['prglength'] < df3['prglength'].median() - 10)]\n",
    "\n",
    "firstbirth = df3[(df3.outcome == 1) & (df3.birthord == 1)]\n",
    "othersbirth = df3[(df3.outcome == 1) & (df3.birthord >= 2)]\n",
    "\n",
    "x = firstbirth['prglength']\n",
    "y = othersbirth['prglength']\n",
    "m= len(x)\n",
    "n= len(y)\n",
    "p = abs(x.mean() - y.mean())\n",
    "N = 1000\n",
    "\n",
    "# Compute p(E|H_0): all come from same population --> bootstrap from the total pool\n",
    "pool = np.concatenate([x,y])\n",
    "np.random.shuffle(pool)\n",
    "diff_0 = np.zeros(shape=(N))\n",
    "for i in range(N):\n",
    "    p1 = [random.choice(pool) for j in range(m)]\n",
    "    p2 = [random.choice(pool) for j in range(n)]\n",
    "    diff_0[i] = abs(np.mean(p1)-np.mean(p2))          # two sided test\n",
    "\n",
    "w1_0 = np.where(diff_0 > p)[0]      # counting how many differences are larger than the observed one\n",
    "p_0 = len(w1_0)/float(N)\n",
    "print('p(E|H_0) =', p_0, '(', p_0*100 ,'%)')\n",
    "\n",
    "# Compute p(E|H_A): firstbirth and othersbirth come from diferent populations --> bootstrap from each group\n",
    "diff_A = np.zeros(shape=(N))\n",
    "for i in range(N):\n",
    "    p1 = [random.choice(x.values) for j in range(m)]\n",
    "    p2 = [random.choice(y.values) for j in range(n)]\n",
    "    diff_A[i] = abs(np.mean(p1)-np.mean(p2))          # two sided test\n",
    "\n",
    "w1_A = np.where(diff_A > p)[0]      # counting how many differences are larger than the observed one\n",
    "p_A = len(w1_A)/float(N)\n",
    "print('p(E|H_A) =', p_A, '(', p_A*100 ,'%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPMDxRZmEAFS"
   },
   "source": [
    "Luego, la probabilidad de \\(P(E | H_A)\\) es aproximadamente 0.5.\n",
    "\n",
    "En ausencia de conocimiento asumiremos que \\(P(H_A) = P(H_0) = 0.5\\).\n",
    "\n",
    "Entonces, podemos calcular las probabilidades posteriores de \\(H_A\\) y \\(H_0\\):\n",
    "\n",
    "$$ P(H_A | E) = \\frac{P(E|H_A) P(H_A)}{P(E)}$$\n",
    "\n",
    "$$ P(H_0 | E) = \\frac{P(E|H_0) P(H_0)}{P(E)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDDujF-nEAFS",
    "outputId": "48cf06d6-1b89-478d-c329-41b0363ca2b2"
   },
   "outputs": [],
   "source": [
    "print('P(H_A|E):', 0.5 * 0.5 / (0.5 * 0.5 + 0.02 * 0.5))\n",
    "print('P(H_0|E):', 0.02 * 0.5 / (0.5 * 0.5 + 0.02 * 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kneOataaEAFS"
   },
   "source": [
    "Así, al tener en cuenta una nueva evidencia, hemos aumentado nuestra creencia en el efecto \\(H_A\\) del 50% al 96%. Esto no es una regla de decisión, sino un cambio en nuestro conocimiento. Tiene sentido: ¡la evidencia apoya la hipótesis!\n",
    "\n",
    "En nuestro problema, basado en el conocimiento experto, también podría tener sentido considerar que \\(P(H_A) = 0.01\\) y \\(P(H_0) = 0.99\\). En este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6MdpDucEAFS",
    "outputId": "f7a5515c-6673-4b45-a7b4-ee2855a01934"
   },
   "outputs": [],
   "source": [
    "print('H_A:', 0.5 * 0.01 / (0.5 * 0.01 + 0.02 * 0.99))\n",
    "print('H_0:', 0.02 * 0.99 / (0.5 * 0.01 + 0.02 * 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OhnCx0SEAFT"
   },
   "source": [
    "Hemos aumentado nuestra creencia en el efecto \\(H_A\\) del 1% al 20%, ¡pero todavía podemos creer en \\(H_0\\)!\n",
    "\n",
    "El cambio depende en gran medida de nuestra creencia previa:\n",
    "\n",
    "<center><small>Imagen de: Sellke et al. \"Calibration of ρ values for testing precise null hypotheses.\" Am. Stat. 55.1 (2001): 62-71.</small></center>\n",
    "\n",
    "<img src=\"./images/p-graphic.jpg\" width=\"600\"/>\n",
    "\n",
    "# Inferencia Bayesiana\n",
    "\n",
    "(de [*Bayesian Methods for Hackers, Cam Davidson-Pilon, 2013*](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/))\n",
    "\n",
    "Supongamos, de manera ingenua, que no estás seguro sobre la probabilidad de obtener cara en un lanzamiento de moneda. Crees que hay alguna proporción verdadera subyacente, llamémosla \\(θ \\in [0,1]\\), pero no tienes una opinión previa sobre qué podría ser \\(θ\\).\n",
    "\n",
    "Comenzamos a lanzar una moneda y registrar las observaciones: ya sea ``H`` o ``T``. Estos son nuestros datos observados.\n",
    "\n",
    "Una pregunta interesante es cómo cambia nuestra inferencia a medida que observamos más y más datos. Más específicamente, **¿cómo se ven nuestras probabilidades posteriores cuando tenemos pocos datos, versus cuando tenemos muchos datos**?\n",
    "\n",
    "> **Suposición**: nuestras distribuciones (paramétricas) son modelos generativos del mundo.\n",
    "\n",
    "En teoría de probabilidad y estadística, la **distribución de Bernoulli**, nombrada así por el científico suizo Jacob Bernoulli, es la distribución de probabilidad de una variable aleatoria que toma el valor 1 con probabilidad de éxito \\(θ\\) y el valor 0 con probabilidad de fracaso \\(1-θ\\).\n",
    "\n",
    "La distribución de probabilidad, sobre los posibles resultados \\(k\\), es:\n",
    "$$P(k|θ)=θ^k (1−θ)^{1−k}$$\n",
    "donde \\(k∈\\{0,1\\}\\) y \\(θ∈[0,1]\\).\n",
    "\n",
    "Podemos usar la función de verosimilitud de Bernoulli para determinar la probabilidad de ver una secuencia particular de \\(N\\) lanzamientos, dada por el conjunto \\({k_1,...,k_N}\\).\n",
    "\n",
    "Dado que cada uno de estos lanzamientos es independiente de cualquier otro, la probabilidad de que ocurra la secuencia es simplemente el producto de la probabilidad de cada lanzamiento (distribución binomial).\n",
    "\n",
    "Si tenemos un parámetro de equidad particular \\(θ\\), entonces la probabilidad de ver esta corriente particular de lanzamientos, dado \\(θ\\), es:\n",
    "$$ P(\\{k_1,...,k_N\\} | θ ) =  \\prod_i P(k_i|θ) = \\prod_i θ^{k_i} (1−θ)^{1−k_i} $$\n",
    "\n",
    "¿Qué pasa si estamos interesados en el número de caras, digamos, en \\(N\\) lanzamientos?\n",
    "\n",
    "Si denotamos por \\(z\\) el número de caras que aparecen, entonces la fórmula anterior se convierte en:\n",
    "\n",
    "$$ P(z,N|θ) = θ^{z} (1−θ)^{N-z} $$\n",
    "Es decir, la probabilidad de ver \\(z\\) caras, en \\(N\\) lanzamientos, asumiendo un parámetro de equidad \\(θ\\).\n",
    "\n",
    "Usaremos esta fórmula cuando lleguemos a determinar nuestra distribución de creencias posteriores.\n",
    "\n",
    "## Regla de Bayes para la Inferencia Bayesiana\n",
    "\n",
    "$$P(θ|D)=\\frac{P(D|θ)P(θ)}{P(D)}$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "+ \\(P(θ)\\) es el prior. Nuestra vista previa sobre la probabilidad de cuán justa es la moneda.\n",
    "\n",
    "+ \\(P(θ|D)\\) es el posterior.\n",
    "\n",
    "+ \\(P(D|θ)\\) es la verosimilitud. Si supiéramos que la moneda es justa, esto nos dice la probabilidad de ver un número de caras en un número particular de lanzamientos.\n",
    "\n",
    "+ \\(P(D)\\) es la evidencia. Si tuviéramos múltiples vistas de cuán justa es la moneda (pero no lo supiéramos con certeza), entonces esto nos dice la probabilidad de ver una cierta secuencia de lanzamientos para todas las posibilidades de nuestra creencia en la equidad de la moneda.\n",
    "\n",
    "Estamos interesados en la probabilidad de que la moneda salga cara como una función del parámetro de equidad subyacente \\(θ\\).\n",
    "\n",
    "En cuanto a la verosimilitud:\n",
    "\n",
    "$$ P(D|θ) = P(z,N|θ) = θ^{z} (1−θ)^{N-z} $$\n",
    "\n",
    "En cuanto al prior, vamos a elegir la distribución beta:\n",
    "\n",
    "$$ P(θ | \\alpha, \\beta)=  \\frac{θ^{\\alpha-1} (1−θ)^{\\beta -1}}{B(\\alpha, \\beta)}  $$ \n",
    "\n",
    "donde el término en el denominador está presente para actuar como una constante normalizadora para que el área bajo la PDF sume realmente a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "DVrc6amCflBB",
    "outputId": "89553eba-9ac6-4e6e-d998-81501dc6efab"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Define the distribution parameters to be plotted\n",
    "alpha_values = [0.5, 1.0, 3.0, 0.5]\n",
    "beta_values = [0.5, 1.5, 3.0, 1.5]\n",
    "linestyles = ['-', '--', ':', '-.']\n",
    "x = np.linspace(0, 1, 1002)[1:-1]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# plot the distributions\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "\n",
    "for a, b, ls in zip(alpha_values, beta_values, linestyles):\n",
    "    dist = beta(a, b)\n",
    "\n",
    "    plt.plot(x, dist.pdf(x), ls=ls, c='black',\n",
    "             label=r'$\\alpha=%.1f,\\ \\beta=%.1f$' % (a, b))\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\alpha,\\beta)$')\n",
    "plt.title('Beta Distribution')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u4tKqEPEAFT"
   },
   "source": [
    "La razón más importante para elegir una distribución beta es porque es un **prior conjugado** para la distribución de Bernoulli.\n",
    "\n",
    "En la regla de Bayes mencionada anteriormente, podemos ver que la distribución posterior es proporcional al producto de la distribución prior y la función de verosimilitud:\n",
    "\n",
    "$$ P(θ|D) \\propto P(D|θ)P(θ) $$\n",
    "\n",
    "Un **prior conjugado** es una elección de distribución prior que, cuando se combina con un tipo específico de función de verosimilitud, proporciona una distribución posterior que es de la misma familia que la distribución prior.\n",
    "\n",
    "> El prior y el posterior tienen la misma familia de distribución de probabilidad, pero con parámetros diferentes.\n",
    "\n",
    "Si nuestro prior está dado por \\( \\text{beta}(θ|α,β) \\) y observamos \\( z \\) caras en \\( N \\) lanzamientos posteriormente, entonces el posterior está dado por \\( \\text{beta}(θ|z+α,N−z+β) \\).\n",
    "\n",
    "A continuación, graficamos una secuencia de actualizaciones de probabilidades posteriores a medida que observamos cantidades crecientes de datos (lanzamientos de moneda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9V-9S12MEAFT",
    "outputId": "7f02652a-afe1-40f4-cfd7-fb012e7c9065"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "figsize(10, 9)\n",
    "\n",
    "# we use a (continous) prior for p by using the beta function\n",
    "dist = stats.beta\n",
    "\n",
    "n_trials = [0,1,2,3,4,5,8,15, 50, 500]\n",
    "\n",
    "# synthetic data generation\n",
    "# random number generation with a Bernoulli distribution with p=0.5\n",
    "# the probability of this sequence is modelled by the binomial distribution\n",
    "data = stats.bernoulli.rvs(0.5, size = n_trials[-1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "Lt0yNrdWEAFT",
    "inputHidden": false,
    "outputHidden": false,
    "outputId": "9bdcec11-5370-4e48-b3c5-0b8edba6402d"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "for k, N in enumerate(n_trials):\n",
    "    sx = plt.subplot( len(n_trials)/2, 2, k+1)\n",
    "    plt.xlabel(\"$p$, probability of heads\") if k in [0,len(n_trials)-1] else None\n",
    "    plt.setp(sx.get_yticklabels(), visible=False)\n",
    "    \n",
    "    # counting the number of heads\n",
    "    heads = data[:N].sum()\n",
    "    \n",
    "    # in this case the posterior can be analitically computed\n",
    "    # because the conjugate prior of the Binomial distribution\n",
    "    # is a Beta distribution \n",
    "    y = dist.pdf(x, 1 + heads, 1 + N - heads )\n",
    "    \n",
    "    plt.plot( x, y, label= \"observe %d tosses,\\n %d heads\"%(N,heads) )\n",
    "    plt.fill_between( x, 0, y, color=\"#348ABD\", alpha = 0.4 )\n",
    "    plt.vlines( 0.5, 0, 4, color = \"k\", linestyles = \"--\", lw=1 )\n",
    "    leg = plt.legend()\n",
    "    leg.get_frame().set_alpha(0.4)\n",
    "    plt.autoscale(tight = True)\n",
    "\n",
    "plt.suptitle( \"Bayesian updating of posterior probabilities\", y = 1.02, fontsize = 14);\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjcswZklEAFU"
   },
   "source": [
    "## Recordatorio: PDFs Populares\n",
    "*(Fuente: https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)*\n",
    "\n",
    "Supongamos que $Z$ es una variable aleatoria. Entonces, asociada con $Z$ hay una *función de distribución de probabilidad* que asigna probabilidades a los diferentes resultados que $Z$ puede tomar. Gráficamente, una distribución de probabilidad es una curva donde la probabilidad de un resultado es proporcional a la altura de la curva.\n",
    "\n",
    "### Caso Discreto\n",
    "\n",
    "Si $Z$ es discreta, entonces su distribución se llama *función de masa de probabilidad*, que mide la probabilidad de que $Z$ tome el valor $k$, denotado $P(Z=k)$.\n",
    "\n",
    "Hay muchas funciones de masa de probabilidad populares, pero introduzcamos la primera función de masa de probabilidad muy útil.\n",
    "\n",
    "Decimos que $Z$ sigue una distribución *Poisson* si:\n",
    "\n",
    "$$P(Z = k) =\\frac{ \\lambda^k e^{-\\lambda} }{k!}, \\; \\; k=0,1,2, \\dots $$\n",
    "\n",
    "Puede expresar la **probabilidad de un número dado de eventos que ocurren en un intervalo de tiempo y/o espacio fijo si estos eventos ocurren con una tasa promedio conocida e independientemente del tiempo desde el último evento**.\n",
    "\n",
    "$\\lambda$ se llama parámetro de la distribución, y controla la forma de la distribución. Para la distribución de Poisson, $\\lambda$ puede ser cualquier número positivo. Al aumentar $\\lambda$, añadimos más probabilidad a valores mayores y, disminuyendo $\\lambda$, añadimos más probabilidad a valores menores. Uno puede describir $\\lambda$ como la *intensidad* de la distribución de Poisson.\n",
    "\n",
    "A diferencia de $\\lambda$, que puede ser cualquier número positivo, el valor $k$ en la fórmula anterior debe ser un entero no negativo, es decir, $k$ debe tomar valores 0, 1, 2, etc. Esto es muy importante, porque si quisieras modelar una población no tendría sentido hablar de poblaciones con 4.25 o 5.612 miembros.\n",
    "\n",
    "Una propiedad útil de la distribución de Poisson es que su valor esperado es igual a su parámetro, es decir:\n",
    "\n",
    "$$E\\large[ \\;Z\\; | \\; \\lambda \\;\\large] = \\lambda $$\n",
    "\n",
    "Esta propiedad se utiliza a menudo, por lo que es útil recordarla. A continuación, graficamos la distribución de masa de probabilidad para diferentes valores de $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "p_Fa2L5hEAFU",
    "outputId": "33e9fe76-18dd-4fe7-dabb-7549a3efb959"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12.5, 4))\n",
    "\n",
    "import scipy.stats as stats\n",
    "a = np.arange(16)\n",
    "poi = stats.poisson\n",
    "lambda_ = [1.5, 4.25]\n",
    "colours = [\"#348ABD\", \"#A60628\",]\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[0]), color=colours[0],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[0], alpha=0.60,\n",
    "        edgecolor=colours[0], lw=\"3\")\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[1]), color=colours[1],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[1], alpha=0.60,\n",
    "        edgecolor=colours[1], lw=\"3\")\n",
    "\n",
    "\n",
    "plt.xticks(a + 0.4, a)\n",
    "plt.legend()\n",
    "plt.ylabel(\"probability of $k$\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.title(\"Probability mass function of a Poisson random variable; differing $\\lambda$ values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEOChydAEAFU"
   },
   "source": [
    "### Caso Continuo\n",
    "En lugar de una función de masa de probabilidad, una variable aleatoria continua tiene una *función de densidad de probabilidad*.\n",
    "\n",
    "Un ejemplo de variable aleatoria continua es una variable aleatoria con **densidad exponencial**. La función de densidad para una variable aleatoria exponencial se ve así:\n",
    "\n",
    "$$f_Z(z | \\lambda) = \\lambda e^{-\\lambda z }, \\;\\; z\\ge 0$$\n",
    "\n",
    "Al igual que una variable aleatoria de Poisson, una variable aleatoria exponencial solo puede tomar valores no negativos. Pero a diferencia de una variable de Poisson, la exponencial puede tomar *cualquier* valor no negativo, incluidos valores no enteros como 4.25 o 5.612401.\n",
    "\n",
    "Esta propiedad la hace una mala elección para datos de conteo, que deben ser enteros, pero una excelente elección para datos de tiempo, datos de temperatura o cualquier otra variable *precisa y positiva*. El gráfico a continuación muestra dos funciones de densidad de probabilidad con diferentes valores de $\\lambda$.\n",
    "\n",
    "Dado un $\\lambda$ específico, el valor esperado de una variable aleatoria exponencial es igual al inverso de $\\lambda$, es decir:\n",
    "\n",
    "$$E[\\; Z \\;|\\; \\lambda \\;] = \\frac{1}{\\lambda}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "z5ARpTcEEAFU",
    "outputId": "26d43443-86bf-4a6e-887d-fd278df6946d"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "a = np.linspace(0, 4, 100)\n",
    "expo = stats.expon\n",
    "\n",
    "mean = [0.5, 1]\n",
    "\n",
    "for l, c in zip(mean, colours):\n",
    "    plt.plot(a, expo.pdf(a, scale=1. / l), lw=3,\n",
    "             color=c, label=\"$\\lambda = %.1f$\" % l)\n",
    "    plt.fill_between(a, expo.pdf(a, scale=1. / l), color=c, alpha=.33)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"PDF at $z$\")\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.title(\"Probability density function of an Exponential random variable;\\\n",
    " differing $\\lambda$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZHdC8PvEAFU"
   },
   "source": [
    "### Pero, ¿qué es $\\lambda \\;$?\n",
    "\n",
    "**Esta pregunta es lo que motiva a la estadística**. En el mundo real, $\\lambda$ está oculto para nosotros.\n",
    "\n",
    "Solo vemos $Z$, y debemos retroceder para intentar determinar $\\lambda$. El problema es difícil porque no hay una relación uno a uno de $Z$ a $\\lambda$. Se han creado muchos métodos diferentes para resolver el problema de estimar $\\lambda$, pero dado que $\\lambda$ nunca se observa realmente, ¡nadie puede decir con certeza cuál método es el mejor!\n",
    "\n",
    "La inferencia Bayesiana se ocupa de las *creencias* sobre lo que podría ser $\\lambda$. En lugar de tratar de adivinar $\\lambda$ exactamente, solo podemos hablar de lo que es probable que sea $\\lambda$ asignando una distribución de probabilidad a $\\lambda$.\n",
    "\n",
    "## Programación Probabilística\n",
    "\n",
    "La programación probabilística permite la especificación flexible y el ajuste de modelos estadísticos bayesianos.\n",
    "\n",
    "PyMC3 es un nuevo marco de PP de código abierto con una sintaxis intuitiva y legible, pero poderosa, que se acerca a la sintaxis natural que los estadísticos usan para describir modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "829QDPudRyx5",
    "outputId": "a926d4a8-218f-41f7-e8a5-8e0d9abf3e62"
   },
   "outputs": [],
   "source": [
    "!apt-get install python3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rhi_xE9rQ-l-",
    "outputId": "e0fa0f81-18dd-4c31-b828-94eab416b084"
   },
   "outputs": [],
   "source": [
    "!pip install pymc3\n",
    "!pip install patsy\n",
    "import pymc3 as pm  \n",
    "import numpy as np  \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1WEG5C6Q-l_"
   },
   "source": [
    "Para introducir la definición del modelo, el ajuste y el análisis posterior, primero consideramos un simple **modelo de regresión lineal Bayesiano** con priors normales en los parámetros.\n",
    "\n",
    "Estamos interesados en predecir los resultados $Y$ como observaciones distribuidas normalmente con $\\mu$ que es una función lineal de dos variables predictoras, $X_1$ y $X_2$:\n",
    "\n",
    "$$ Y \\sim \\mathcal{N} (\\mu, \\sigma^2)$$\n",
    "$$ \\mu = \\alpha + \\beta_1 X_1 + \\beta_2 X_2 $$\n",
    "\n",
    "Aplicaremos priors normales con media cero y varianza de 10 a ambos coeficientes de regresión, lo que corresponde a una información débil respecto a los valores verdaderos de los parámetros.\n",
    "\n",
    "Dado que las varianzas deben ser positivas, también elegiremos una distribución normal media (distribución normal acotada por debajo en cero) como el prior para $\\sigma$:\n",
    "\n",
    "$$ \\alpha \\sim \\mathcal{N}(0,10)$$\n",
    "$$ \\beta_i \\sim \\mathcal{N}(0,10)$$\n",
    "$$ \\sigma \\sim \\mathcal{|N}(0,10)|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "ZgwTiCW1Q-l_",
    "outputId": "1efc236a-61a1-4c32-ac3c-a694e4d41f56"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "\n",
    "# Intialize random number generator\n",
    "from numpy import random\n",
    "np.random.seed(123)\n",
    "\n",
    "# True parameter values\n",
    "\n",
    "alpha, sigma = 1, 1\n",
    "beta = [1, 2.5]\n",
    "size = 1000\n",
    "X1 = random.rand(size)\n",
    "X2 = random.rand(size)/5.0\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(10,4))\n",
    "axes[0].scatter(X1, Y)\n",
    "axes[1].scatter(X2, Y)\n",
    "axes[0].set_ylabel('Y'); axes[0].set_xlabel('X1'); axes[1].set_xlabel('X2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "xF5KMTp0Q-l_",
    "outputId": "24e5bb67-1009-41c0-f12c-d6714b5ec34b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X1,X2,Y) # plot the point (2,3,4) on the figure\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulC1PINgQ-l_"
   },
   "source": [
    "### Especificación del modelo\n",
    "\n",
    "Especificar este modelo en PyMC3 es sencillo porque la sintaxis es muy cercana a la notación estadística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OB_y5PICQ-l_"
   },
   "outputs": [],
   "source": [
    "from pymc3 import Model, Normal, HalfNormal\n",
    "\n",
    "# container for the model random variables\n",
    "basic_model = Model()\n",
    "\n",
    "# all PyMC3 objects introduced in the indented \n",
    "# code block below the with statement are added to the model behind the scenes\n",
    "with basic_model:\n",
    "    \n",
    "    # Priors (stochastic random variables) for unknown model parameters\n",
    "    alpha = Normal('alpha', mu=0, sd=10)\n",
    "    beta = Normal('beta', mu=0, sd=10, shape=2)\n",
    "    sigma = HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta[0]*X1 + beta[1]*X2\n",
    "    \n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = Normal('Y_obs', mu=mu, sd=sigma, observed=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5SH5UsGQ-l_"
   },
   "source": [
    "### Ajuste del modelo\n",
    "\n",
    "Habiendo especificado completamente nuestro modelo, el siguiente paso es obtener **estimaciones posteriores para las variables desconocidas en el modelo**.\n",
    "\n",
    "**Idealmente, podríamos calcular las estimaciones posteriores de forma analítica, pero para la mayoría de los modelos no triviales, esto no es factible.**\n",
    "\n",
    "Consideraremos dos enfoques, cuya idoneidad depende de la estructura del modelo y los objetivos del análisis:\n",
    "+ encontrar el punto de máximo a posteriori (MAP) utilizando métodos de optimización, y\n",
    "+ calcular resúmenes basados en muestras extraídas de la distribución posterior utilizando métodos de muestreo de Cadenas de Markov Monte Carlo (MCMC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "bs1r_GuCQ-mA",
    "outputId": "73e8df5b-ca54-4c15-b676-22f81bc931d4"
   },
   "outputs": [],
   "source": [
    "# Maximum a posteriori method (maximum of the log-posterior)\n",
    "\n",
    "from pymc3 import find_MAP\n",
    "\n",
    "map_estimate = find_MAP(model=basic_model)\n",
    "print(map_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjMbUTA-Q-mA"
   },
   "source": [
    "PyMC3 incluye algoritmos de muestreo estándar como Metropolis-Hastings adaptativo y muestreo por rebanadas adaptativo, pero el método de paso más capaz de PyMC3 es el Muestreador No-U-Turn (NUTS).\n",
    "\n",
    "NUTS es especialmente útil en modelos que tienen muchos parámetros continuos,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "uw1ec27rQ-mA",
    "outputId": "4c98dbe6-dd8b-4997-de86-f4ae4785bfcb"
   },
   "outputs": [],
   "source": [
    "# sampling method\n",
    "\n",
    "from pymc3 import sample\n",
    "\n",
    "with basic_model:\n",
    "    \n",
    "    # obtain starting values via MAP\n",
    "    start = find_MAP(model=basic_model)\n",
    "    \n",
    "    # draw 2000 posterior samples\n",
    "    trace = sample(2000, start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL6eFpcUQ-mD"
   },
   "source": [
    "La función `sample` ejecuta el o los métodos `step` asignados (o pasados) durante el número dado de iteraciones y devuelve un objeto `Trace` que contiene las muestras recogidas, en el orden en que fueron recogidas.\n",
    "\n",
    "El objeto `Trace` puede ser consultado de manera similar a un diccionario que contiene un mapa de nombres de variables a `numpy.arrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fA5GnbuhQ-mD",
    "outputId": "f7b540b1-ba8b-4249-d838-c2c33c58c36d"
   },
   "outputs": [],
   "source": [
    "trace['alpha'][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cQowvLJQ-mE"
   },
   "source": [
    "### Análisis posterior\n",
    "\n",
    "PyMC3 proporciona funciones de trazado y resumen para inspeccionar la salida del muestreo. Un gráfico posterior simple se puede crear usando `traceplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "oEFmUnJOQ-mE",
    "outputId": "8b1b7146-8540-456a-dafd-9d2f8ad8e5ff"
   },
   "outputs": [],
   "source": [
    "from pymc3 import traceplot\n",
    "\n",
    "traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "VEUQdC6LQ-mE",
    "outputId": "4b450842-f889-4b84-8367-0544016ed846"
   },
   "outputs": [],
   "source": [
    "from pymc3 import summary\n",
    "\n",
    "summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7R89BjBEAFY"
   },
   "source": [
    "## Ejemplo: Inferir comportamiento a partir de datos de mensajes de texto.\n",
    "\n",
    "> Se te proporciona una serie de conteos diarios de mensajes de texto de un usuario de tu sistema. Los datos, representados a lo largo del tiempo, aparecen en el gráfico a continuación. Te interesa saber si los hábitos de envío de mensajes de texto del usuario han cambiado con el tiempo, ya sea gradual o repentinamente. ¿Cómo puedes modelar esto? (De hecho, estos son mis propios datos de mensajes de texto. Juzga mi popularidad como desees.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "-rw65b8sEAFY",
    "outputId": "f884c007-3f39-41e7-d364-a75f4849fa49"
   },
   "outputs": [],
   "source": [
    "\n",
    "file = open('txtdata.csv', 'r')\n",
    "\n",
    "count_data = np.loadtxt(file)\n",
    "n_count_data = len(count_data)\n",
    "plt.bar(np.arange(n_count_data), count_data, color=\"#348ABD\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"count of text-msgs received\")\n",
    "plt.title(\"Did the user's texting habits change over time?\")\n",
    "plt.xlim(0, n_count_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "5Gk3ycoOEAFY",
    "outputId": "ef52e5fc-d285-40a4-ae35-e660dd0bad2c"
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    alpha = 1.0/count_data.mean()  # Recall count_data is the\n",
    "                                   # variable that holds our txt counts\n",
    "                                   \n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", alpha)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", alpha)\n",
    "    \n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count_data - 1)\n",
    "\n",
    "with model:\n",
    "    idx = np.arange(n_count_data) # Index\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "\n",
    "with model:\n",
    "    observation = pm.Poisson(\"obs\", lambda_, observed=count_data)\n",
    "    \n",
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(10000, tune=5000, step=step, return_inferencedata=False)\n",
    "\n",
    "lambda_1_samples = trace['lambda_1']\n",
    "lambda_2_samples = trace['lambda_2']\n",
    "tau_samples = trace['tau']\n",
    "\n",
    "figsize(12.5, 10)\n",
    "#histogram of the samples:\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "\n",
    "plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=\"posterior of $\\lambda_1$\", color=\"#A60628\", density=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(r\"\"\"Posterior distributions of the variables\n",
    "    $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(\"$\\lambda_1$ value\")\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=\"posterior of $\\lambda_2$\", color=\"#7A68A6\", density=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(\"$\\lambda_2$ value\")\n",
    "\n",
    "plt.subplot(313)\n",
    "w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
    "plt.hist(tau_samples, bins=n_count_data, alpha=1,\n",
    "         label=r\"posterior of $\\tau$\",\n",
    "         color=\"#467821\", weights=w, rwidth=2.)\n",
    "plt.xticks(np.arange(n_count_data))\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim([0, .75])\n",
    "plt.xlim([35, len(count_data)-20])\n",
    "plt.xlabel(r\"$\\tau$ (in days)\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "QWoaCIWnQ-mF",
    "outputId": "77aa1d2f-fa0b-4687-d829-a88953b5da2c"
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 5)\n",
    "# tau_samples, lambda_1_samples, lambda_2_samples contain\n",
    "# N samples from the corresponding posterior distribution\n",
    "N = tau_samples.shape[0]\n",
    "expected_texts_per_day = np.zeros(n_count_data)\n",
    "for day in range(0, n_count_data):\n",
    "    # ix is a bool index of all tau samples corresponding to\n",
    "    # the switchpoint occurring prior to value of 'day'\n",
    "    ix = day < tau_samples\n",
    "    # Each posterior sample corresponds to a value for tau.\n",
    "    # for each day, that value of tau indicates whether we're \"before\"\n",
    "    # (in the lambda1 \"regime\") or\n",
    "    #  \"after\" (in the lambda2 \"regime\") the switchpoint.\n",
    "    # by taking the posterior sample of lambda1/2 accordingly, we can average\n",
    "    # over all samples to get an expected value for lambda on that day.\n",
    "    # As explained, the \"message count\" random variable is Poisson distributed,\n",
    "    # and therefore lambda (the poisson parameter) is the expected value of\n",
    "    # \"message count\".\n",
    "    expected_texts_per_day[day] = (lambda_1_samples[ix].sum()\n",
    "                                   + lambda_2_samples[~ix].sum()) / N\n",
    "\n",
    "\n",
    "plt.plot(range(n_count_data), expected_texts_per_day, lw=4, color=\"#E24A33\",\n",
    "         label=\"expected number of text-messages received\")\n",
    "plt.xlim(0, n_count_data)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Expected # text-messages\")\n",
    "plt.title(\"Expected number of text-messages received\")\n",
    "plt.ylim(0, 60)\n",
    "plt.bar(np.arange(len(count_data)), count_data, color=\"#348ABD\", alpha=0.65,\n",
    "        label=\"observed texts per day\")\n",
    "\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUU_fB0gEAFY"
   },
   "source": [
    "Más información: [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "ak2GyEGiEAFO",
    "zj7UeDLfEAFP",
    "6B6kTVQUEAFP",
    "p0-NXiANEAFQ",
    "J571-GltEAFS",
    "bZHdC8PvEAFU"
   ],
   "name": "12. Bayesian Data Analysis.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
