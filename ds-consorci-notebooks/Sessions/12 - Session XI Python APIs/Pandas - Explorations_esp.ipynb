{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaptive-irrigation",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Installation\" data-toc-modified-id=\"Installation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Installation</a></span></li><li><span><a href=\"#Introduction-to-pandas-data-structures\" data-toc-modified-id=\"Introduction-to-pandas-data-structures-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Introduction to pandas data structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Series</a></span></li><li><span><a href=\"#Dataframes\" data-toc-modified-id=\"Dataframes-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-data-types\" data-toc-modified-id=\"From-data-types-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>From data types</a></span></li><li><span><a href=\"#From-path\" data-toc-modified-id=\"From-path-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>From path</a></span></li><li><span><a href=\"#From-databases\" data-toc-modified-id=\"From-databases-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>From databases</a></span></li></ul></li></ul></li><li><span><a href=\"#Exploratory-analysis-of-a-dataframe\" data-toc-modified-id=\"Exploratory-analysis-of-a-dataframe-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exploratory analysis of a dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Meta-information\" data-toc-modified-id=\"Meta-information-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Meta information</a></span></li><li><span><a href=\"#Previsualization\" data-toc-modified-id=\"Previsualization-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Previsualization</a></span></li><li><span><a href=\"#Order-a-dataframe\" data-toc-modified-id=\"Order-a-dataframe-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Order a dataframe</a></span></li><li><span><a href=\"#NaN-values\" data-toc-modified-id=\"NaN-values-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>NaN values</a></span></li><li><span><a href=\"#Basic-descriptive-statistics\" data-toc-modified-id=\"Basic-descriptive-statistics-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Basic descriptive statistics</a></span></li></ul></li><li><span><a href=\"#Pandas-usual-methods\" data-toc-modified-id=\"Pandas-usual-methods-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pandas usual methods</a></span></li><li><span><a href=\"#Further-materials\" data-toc-modified-id=\"Further-materials-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Further materials</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-academy",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-needle",
   "metadata": {},
   "source": [
    "![pandas](https://media.giphy.com/media/nVsLCrW5iHf6E/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751721df",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Pandas se destaca como la biblioteca preeminente dentro del ecosistema de Python para la manipulación y análisis de datos. Cuenta con velocidad, potencia, flexibilidad, facilidad de uso y la ventaja de ser de código abierto.\n",
    "\n",
    "Pandas fue concebido y desarrollado por **Wes McKinney (TAMBIÉN CONOCIDO COMO DIOS MCKINNEY)**, un analista financiero convertido en desarrollador de software. Wes reconoció la necesidad de una herramienta que pudiera abordar efectivamente los desafíos del análisis de datos en la industria financiera. Su visión era crear una biblioteca de Python que pudiera proporcionar las mismas capacidades de manipulación de datos encontradas en el software de hojas de cálculo populares y bases de datos relacionales.\n",
    "\n",
    "En 2008, Wes McKinney comenzó a trabajar en Pandas mientras estaba en AQR Capital Management. Su pasión y dedicación llevaron al lanzamiento de la primera versión de Pandas en 2009. No tardó mucho en que Pandas ganara tracción en la comunidad de Python, y rápidamente se convirtió en una herramienta esencial para analistas de datos y científicos.\n",
    "\n",
    "**Características clave de Pandas**: Pandas ofrece una serie de características convincentes, incluyendo:\n",
    "\n",
    "- **DataFrame (núcleo)**: Un objeto DataFrame rápido y eficiente para la manipulación de datos sin problemas, completo con indexación integrada.\n",
    "\n",
    "- **Entrada/Salida de Datos**: Lectura y escritura de datos simplificada en varios formatos, como Microsoft Excel, CSV, bases de datos SQL, y más.\n",
    "\n",
    "- **Manipulación de Datos Robusta**: Métodos integrados y eficientes para una amplia gama de manipulaciones de datos, incluyendo el manejo de datos faltantes, subconjuntos, fusión, y más.\n",
    "\n",
    "- **Manejo de Datos Temporales**: Pandas sobresale en la gestión de datos temporales, convirtiéndose en la opción preferida para trabajar con datos de panel (de ahí su nombre).\n",
    "\n",
    "- **Integración**: Integración suave con otras bibliotecas de análisis de datos y aprendizaje automático como scikit-learn, scipy, seaborn y plotly.\n",
    "\n",
    "- **Uso Generalizado**: Pandas goza de una adopción generalizada en sectores privados y académicos, convirtiéndose en una herramienta imprescindible para los entusiastas de los datos.\n",
    "\n",
    "**Potenciando el Análisis de Datos**: Pandas proporciona estructuras de datos de alto nivel y funciones diseñadas para acelerar tu trabajo con datos estructurados o tabulares. Desde su debut en 2010, Pandas ha jugado un papel pivotal en elevar a Python como un entorno robusto y eficiente para el análisis de datos.\n",
    "\n",
    "Los objetos principales de Pandas que encontrarás en esta guía son el DataFrame —una estructura de datos tabular orientada a columnas con etiquetas de filas y columnas intuitivas— y la Serie —un arreglo unidimensional etiquetado.\n",
    "\n",
    "Pandas une los principios de alto rendimiento de NumPy con las capacidades de manipulación de datos versátiles de las hojas de cálculo y bases de datos relacionales, como SQL. Introduce características de indexación sofisticadas que simplifican la remodelación, el corte, la agregación y la selección de subconjuntos de datos.\n",
    "\n",
    "En resumen, Pandas empodera a analistas de datos, científicos y ingenieros para utilizar Python como una herramienta potente para una amplia gama de tareas relacionadas con datos, revolucionando la manera en que se gestiona y analiza los datos estructurados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-nutrition",
   "metadata": {},
   "source": [
    "![image](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Source: [Forbes](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#1ba071616f63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6680d33",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Instalación\n",
    "Lo primero que siempre debes hacer es `pip install pandas`, `conda install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "psychological-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d4f4b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Introducción a las estructuras de datos de pandas\n",
    "Para comenzar con pandas, necesitarás familiarizarte con sus dos estructuras de datos de trabajo: Series y DataFrame. Aunque no son una solución universal para todos los problemas, proporcionan una base sólida y fácil de usar para la mayoría de las aplicaciones.\n",
    "\n",
    "### Series\n",
    "Una Serie es como un arreglo unidimensional, pero con un giro. Contiene una secuencia de valores, similar a lo que encontrarías en arreglos de NumPy, pero también empareja cada valor con una etiqueta conocida como índice. Esta combinación de valores de datos y etiquetas le da a las Series su poder, convirtiéndolas en una herramienta versátil para el almacenamiento y recuperación eficiente de datos.\n",
    "\n",
    "Así es como se crea una Serie básica usando una lista de números:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec68b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [10, 20, 30, 40, 50]\n",
    "series = pd.Series(data)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All methods implicit in serie\n",
    "[i for i in dir(my_series) if \"_\" not in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8006ecb",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "La representación en cadena de una Serie mostrada interactivamente muestra el índice a la izquierda y los valores a la derecha. Dado que no especificamos un índice para los datos, se crea uno predeterminado que consiste en los enteros del 0 al N - 1 (donde N es la longitud de los datos). Puedes obtener la representación en arreglo y el objeto de índice de la Serie a través de sus atributos de valores e índice, respectivamente:\n",
    "\n",
    "Otra forma de pensar en una Serie es como un diccionario ordenado de longitud fija, ya que es un mapeo de valores de índice a valores de datos. Se puede utilizar en muchos contextos en los que se podría usar un diccionario.\n",
    "Si tienes datos contenidos en un dict de Python, puedes crear una Serie a partir de él pasando el dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type for pandas (class)\n",
    "type(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e26526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the length too\n",
    "len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the series, can we use for loops here?\n",
    "series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99576bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values on the series\n",
    "series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access by the index (as before)\n",
    "series[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ede87",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Cuando solo se pasa un dict, el índice String resultante tendrá las claves del dict en orden. Puedes anular esto pasando las claves del dict en el orden en que deseas que aparezcan en el String resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a random dictionary\n",
    "some_data = {\n",
    "    \"Ohio\":4567,\n",
    "    \"Texas\": 5678,\n",
    "    \"Oregon\": 45678,\n",
    "    \"Utah\": 56789,\n",
    "    \"something else\": 43567\n",
    "}\n",
    "\n",
    "# Generate the type series\n",
    "my_series = pd.Series(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1440c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the series\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do your think key and index are the same?\n",
    "list(some_data.keys()) == list(my_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value\n",
    "my_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index\n",
    "my_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a97ba9",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**Manejo de Datos Faltantes**: Al construir una Serie con datos proporcionados y un índice personalizado, Pandas alineará los datos basándose en las etiquetas del índice. Cualquier valor faltante en los datos correspondientes al índice se marcará como NaN (no un número). En Pandas, NaN representa valores perdidos o indefinidos.\n",
    "\n",
    "Por ejemplo, consideremos crear una Serie utilizando datos predefinidos y un índice personalizado. En el siguiente ejemplo, tenemos datos para algunos estados, pero no todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000}\n",
    "states = ['Ohio', 'Texas', 'Oregon', 'Utah', 'California']\n",
    "\n",
    "# Create a Series with provided data and a custom index\n",
    "my_series = pd.Series(data=sdata, index=states)\n",
    "\n",
    "# The resulting Series contains the data for 'Ohio', 'Texas', and 'Oregon'\n",
    "# 'Utah' and 'California' are included in the index but have no data associated, hence they appear as NaN\n",
    "print(my_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff1578",
   "metadata": {},
   "source": [
    "En este ejemplo, la Serie `my_series` se crea con datos de `sdata` y un índice personalizado `states`. Los valores correspondientes a 'Ohio', 'Texas' y 'Oregon' se colocan en consecuencia. Sin embargo, 'Utah' y 'California' están presentes en el índice pero no tienen datos asociados, lo que lleva a valores NaN en la Serie.\n",
    "\n",
    "Puedes acceder a los valores y al índice de una Serie usando los atributos `values` e `index`, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_series.values)  # Displays the values of the Series\n",
    "print(my_series.index)   # Displays the index labels of the Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb021a5",
   "metadata": {},
   "source": [
    "Cuando se trabaja con valores NaN, es importante manejarlos adecuadamente en tu análisis de datos, ya que las operaciones sobre NaN pueden resultar en resultados inesperados. Puedes usar funciones como `isna()` o `fillna()` para detectar y manejar valores faltantes en tu Serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_series.isna())         # Returns a boolean Series indicating NaN values\n",
    "my_series.fillna(0, inplace=True)  # Fills NaN values with a specified value (e.g., 0) in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686773c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Dataframes\n",
    "\n",
    "En Pandas, un DataFrame es una estructura de datos tabular bidimensional, de tamaño mutable y potencialmente heterogénea, con ejes etiquetados (filas y columnas). A menudo se compara con una hoja de cálculo o tabla SQL, ya que proporciona una forma conveniente de almacenar y manipular datos.\n",
    "\n",
    "**Entendiendo los Dataframes**\n",
    "\n",
    "- **Series**: Antes de sumergirnos en los DataFrames, es esencial entender el concepto de Series. Una Serie es un objeto similar a un arreglo unidimensional que puede contener varios tipos de datos. Los DataFrames son esencialmente colecciones de objetos Serie, cada uno representando una columna.\n",
    "\n",
    "- **Columnas**: En un DataFrame, cada Serie representa una columna. Estas columnas pueden contener diferentes tipos de datos, como enteros, flotantes o cadenas.\n",
    "\n",
    "- **Filas**: Las filas en un DataFrame están organizadas por etiquetas de índice. Cada fila corresponde a una entrada específica, y puedes acceder a las filas usando sus etiquetas de índice.\n",
    "\n",
    "Los DataFrames son una herramienta poderosa para la manipulación, análisis y limpieza de datos. Ofrecen una forma estructurada de trabajar con datos, facilitando el filtrado, ordenamiento y cálculo de estadísticas en conjuntos de datos. Exploraremos varias operaciones y funcionalidades de DataFrame en esta guía.\n",
    "\n",
    "#### Desde tipos de datos\n",
    "En Pandas, puedes crear DataFrames a partir de varias fuentes de datos, incluyendo diccionarios, listas, archivos CSV, bases de datos SQL y más. Una forma común de crear un DataFrame es a partir de un diccionario, donde cada clave representa el nombre de una columna y el valor asociado es una lista o arreglo de datos para esa columna.\n",
    "\n",
    "`desde diccionarios con listas como valores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0186c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with columns and data\n",
    "dict_states = {\n",
    "    \"state\": [\"Oregon\", \"Utah\", \"New Mexico\", \"Nebraska\"],\n",
    "    \"year\": [1900, 1898, 2000, 1900],\n",
    "    \"something_else\": [456, \"ssdsd\", 0.023, np.nan]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(dict_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52162b19",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "En este ejemplo, primero importamos las bibliotecas Pandas y NumPy. Luego, creamos un diccionario `dict_states`, donde cada clave representa el nombre de una columna, y el valor asociado es una lista de datos para esa columna. Pasamos este diccionario a `pd.DataFrame()` para crear un DataFrame llamado `df`. Finalmente, mostramos el DataFrame.\n",
    "\n",
    "Cuando usas Jupyter Notebook, los objetos DataFrame de Pandas se muestran como tablas HTML más amigables para el navegador, lo que facilita ver y explorar los datos de manera interactiva. Puedes encontrar más opciones y detalles de personalización para la visualización de DataFrame en la [documentación de Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html).\n",
    "\n",
    "`desde lista de diccionarios`\n",
    "Si creas un DataFrame a partir de una lista de diccionarios:\n",
    "\n",
    "- Cada diccionario dentro de la lista representa una fila en el DataFrame.\n",
    "- Las claves dentro de cada diccionario se convierten en los nombres de las columnas del DataFrame.\n",
    "- Todos los diccionarios en la lista deben tener la misma estructura en términos de claves para asegurar la consistencia.\n",
    "\n",
    "Aquí hay algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Creating a DataFrame with consistent keys in each dictionary\n",
    "dict_states = {\n",
    "    \"state\": [\"Oregon\", \"Utah\", \"New Mexico\", \"Nebraska\"],\n",
    "    \"year\": [1900, 1898, 2000, 1900],\n",
    "    \"something_else\": [456, \"ssdsd\", 0.023, np.nan]\n",
    "}\n",
    "\n",
    "list_of_dictionaries = [\n",
    "    {\"state\":[\"Oregon\", \"Utah\", \"New Mexico\", \"Nebraska\"]}, # Each dictionary represents a row\n",
    "    {\"year\": [1900, 1898, 2000, 1900]}, # Corresponding values for the 'year' column\n",
    "    {\"something_else\": [456, \"ssdsd\", 0.023, np.nan]}, # Corresponding values for the 'something_else' column\n",
    "]\n",
    "\n",
    "# Creating a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(list_of_dictionaries)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3df90706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Creating a DataFrame with varying dictionary structures\n",
    "list_of_dictionaries = [\n",
    "    {\"state\": \"Oregon\", \"year\": 1900, \"something_else\": \"oiuyghj\"}, # Each dictionary represents a row\n",
    "    {\"state\": \"Utah\", \"year\": 1989, \"something_else\": 678}, # Varying structures among dictionaries\n",
    "    {\"state\": \"New Mexico\", \"year\": 456, \"something_else\": 87, \"extra\": 98765} # Extra key 'extra' in one dictionary\n",
    "]\n",
    "\n",
    "# Creating a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(list_of_dictionaries)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c63fee",
   "metadata": {},
   "source": [
    "En el primer ejemplo, creamos un DataFrame `df` usando una lista de diccionarios `list_of_dictionaries`, donde cada diccionario representa una fila con columnas que coinciden con las claves. En el segundo ejemplo, mostramos que puedes tener variaciones en la estructura de cada diccionario siempre y cuando tengan claves comunes.\n",
    "\n",
    "Para más detalles, puedes referirte a la [documentación de pandas sobre `from_dict`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html).\n",
    "\n",
    "#### Desde ruta\n",
    "\n",
    "`.csv`\n",
    "\n",
    "En este ejemplo, cargamos datos en un DataFrame `df` usando la función `pd.read_csv()`. Cargar datos desde archivos CSV es una operación común al trabajar con Pandas, ya que te permite traer datos externos a un DataFrame para su análisis y manipulación. El DataFrame resultante, `df`, contiene los datos estructurados del archivo CSV, haciéndolos accesibles para una exploración y análisis posteriores.\n",
    "\n",
    "**Conjunto de Datos de Precios de Aguacate**: El conjunto de datos \"Precios de Aguacate\", obtenido de Kaggle, es un conjunto de datos ampliamente utilizado para proyectos de análisis de datos y aprendizaje automático. Proporciona datos históricos sobre precios y ventas de aguacates en varias regiones de los Estados Unidos. Este conjunto de datos es valioso para entender las tendencias en los precios de los aguacates, los volúmenes de ventas y su relación con diferentes factores.\n",
    "\n",
    "**Atributos Clave**:\n",
    "\n",
    "- **Columnas**: El conjunto de datos incluye varias columnas de información. Algunas de las columnas clave típicamente encontradas en este conjunto de datos incluyen:\n",
    "    - **Date**: La fecha de observación.\n",
    "    - **AveragePrice**: El precio promedio de los aguacates.\n",
    "    - **Total Volume**: Volumen total de aguacates vendidos.\n",
    "    - **4046**: Volumen de aguacates Hass pequeños vendidos.\n",
    "    - **4225**: Volumen de aguacates Hass grandes vendidos.\n",
    "    - **4770**: Volumen de aguacates Hass extra grandes vendidos.\n",
    "    - **Total Bags**: Total de bolsas de aguacates vendidas.\n",
    "    - **Small Bags**: Bolsas de aguacates pequeños vendidas.\n",
    "    - **Large Bags**: Bolsas de aguacates grandes vendidas.\n",
    "    - **XLarge Bags**: Bolsas de aguacates extra grandes vendidas.\n",
    "    - **Type**: El tipo de aguacates, a menudo categorizados como convencionales u orgánicos.\n",
    "    - **Region**: La región o ciudad dentro de los Estados Unidos donde se registraron los datos.\n",
    "\n",
    "- **Rango de Fechas**: El conjunto de datos abarca un rango de fechas, lo que permite el análisis de series de tiempo. Puedes examinar cómo cambian los precios y ventas de aguacates a lo largo de diferentes estaciones y años.\n",
    "\n",
    "- **Regiones**: Se proporciona información para varias regiones o ciudades a través de los Estados Unidos, lo que permite el análisis de variaciones de precios y ventas en diferentes mercados.\n",
    "\n",
    "- **Tipos**: El conjunto de datos distingue entre diferentes tipos de aguacates, como convencionales y orgánicos, lo que puede ser útil para comparar tendencias de precios entre estas categorías.\n",
    "\n",
    "- **Volumen**: Están disponibles datos sobre el volumen total de aguacates vendidos. Esta métrica de volumen se utiliza a menudo para analizar la demanda del mercado.\n",
    "\n",
    "- **Precio Promedio**: El conjunto de datos contiene el precio promedio de los aguacates, una métrica fundamental para entender las tendencias de precios.\n",
    "\n",
    "**Casos de Uso**:\n",
    "\n",
    "- Este conjunto de datos se utiliza comúnmente para aprender y practicar el análisis de datos, visualización de datos y modelado de regresión en proyectos de ciencia de datos y aprendizaje automático.\n",
    "\n",
    "- Sirve como un recurso valioso para entender cómo trabajar con datos del mundo real, extraer conocimientos y tomar decisiones basadas en datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(\"../datasets/avocado_kaggle.csv\")\n",
    "\n",
    "# Show dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985db2a6",
   "metadata": {},
   "source": [
    "`.xlsx`, `.xls`, `.xlsm`, `.xlsb`, `.odf`, `.ods`, `.odt`\n",
    "\n",
    "Pandas, una poderosa biblioteca de manipulación de datos en Python, proporciona una funcionalidad robusta para leer y escribir datos desde y hacia archivos Excel con varias extensiones. Los archivos Excel se utilizan comúnmente para almacenar datos estructurados, lo que los convierte en un formato popular para compartir y analizar datos tanto en entornos empresariales como de investigación. (a veces es demasiado lento...)\n",
    "\n",
    "Pandas simplifica el proceso de manejo de archivos Excel, permitiéndote integrar sin problemas datos de hojas de cálculo en tus flujos de trabajo de análisis de datos. Ya sea que estés tratando con archivos `.xls` clásicos, libros de trabajo `.xlsx` modernos o otros formatos compatibles con Excel como `.xlsm`, `.xlsb`, `.odf`, `.ods` y `.odt`, Pandas ofrece herramientas versátiles para importar y exportar datos.\n",
    "\n",
    "**Características Clave**:\n",
    "\n",
    "- **Leer Datos de Excel**: Pandas proporciona funciones para leer datos de Excel en DataFrames, preservando la estructura y el formato de las hojas de trabajo. Puedes leer datos de manera eficiente de múltiples hojas dentro de un libro de trabajo.\n",
    "\n",
    "- **Escribir Datos en Excel**: Pandas te permite escribir DataFrames de vuelta a archivos Excel, permitiéndote guardar tus datos junto con cualquier modificación o análisis que hayas realizado.\n",
    "\n",
    "- **Compatibilidad**: Pandas soporta varias extensiones de archivos Excel, incluyendo `.xls`, `.xlsx`, `.xlsm`, `.xlsb`, `.odf`, `.ods` y `.odt`, asegurando compatibilidad con diferentes versiones y formatos de Excel.\n",
    "\n",
    "- **Preservación de Datos**: Al leer archivos Excel, Pandas retiene tipos de datos, fórmulas, estilos de celda y otros atributos, asegurando la integridad de los datos.\n",
    "\n",
    "- **Manipulación de Datos**: Una vez que los datos están cargados en DataFrames de Pandas, puedes usar las extensas capacidades de manipulación y análisis de datos de Pandas para explorar, limpiar, transformar y visualizar tus datos.\n",
    "\n",
    "**Casos de Uso**:\n",
    "\n",
    "- Extracción de Datos: Extraer datos estructurados de archivos Excel para realizar análisis, informes o visualización.\n",
    "\n",
    "- Integración de Datos: Combinar datos de múltiples hojas o libros de trabajo de Excel en un único conjunto de datos consolidado.\n",
    "\n",
    "- Exportación de Datos: Guardar los resultados del análisis de datos realizado con Pandas de vuelta en archivos Excel para compartir o procesar más adelante.\n",
    "\n",
    "- Automatización: Automatizar tareas de extracción y manipulación de datos incorporando Pandas en tu canal de datos o flujo de trabajo.\n",
    "\n",
    "Pandas hace que trabajar con archivos Excel sea muy fácil, permitiéndote aprovechar el poder de Python para tus proyectos de análisis de datos mientras interactúas sin problemas con datos de Excel.\n",
    "\n",
    "Para comenzar, explora la extensa documentación de Pandas sobre [Entrada/Salida de Archivos Excel](https://pandas.pydata.org/docs/reference/io.html#excel) para aprender sobre los diversos métodos y opciones disponibles para leer y escribir archivos Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707974d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another dataset\n",
    "df_from_excel = pd.read_excel(\"../datasets/Online Retail.xlsx\", engine=\"openpyxl\", nrows=5)\n",
    "df_from_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9178b7",
   "metadata": {},
   "source": [
    "`Leyendo diferentes sheets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0407b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the Excel file\n",
    "excel_file_path = \"../datasets/Online Retail.xlsx\"\n",
    "\n",
    "# Reading the Default Tab (First One)\n",
    "# Use the read_excel function to read the first sheet of the Excel file (default behavior)\n",
    "df_default_tab = pd.read_excel(excel_file_path, engine=\"openpyxl\", nrows=5)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df_default_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfeb8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Another Tab (e.g., \"new_tab\")\n",
    "# Specify the sheet name as a string to read a specific sheet from the Excel file\n",
    "df_new_tab = pd.read_excel(excel_file_path, engine=\"openpyxl\", sheet_name=\"new_tab\", nrows=5)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame from the \"new_tab\" sheet\n",
    "df_new_tab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9ea58",
   "metadata": {},
   "source": [
    "#### Desde bases de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffcaa3c",
   "metadata": {},
   "source": [
    "`sql`: [docs](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2380f09",
   "metadata": {},
   "source": [
    "```python\n",
    "from sqlite3 import connect\n",
    "\n",
    "conn = connect(':memory:')\n",
    "df = pd.read_sql('SELECT column_1, column_2 FROM sample_data', conn)\n",
    "\n",
    "df.to_sql('test_data', conn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92c595",
   "metadata": {},
   "source": [
    "`mongodb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431cee4b",
   "metadata": {},
   "source": [
    "```python\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.database_name\n",
    "collection = db.collection_name\n",
    "data = pd.DataFrame(list(collection.find()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7fbf8",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Análisis exploratorio de un dataframe\n",
    "\n",
    "En esta sección, nos adentraremos en el mundo del análisis exploratorio de datos (EDA) utilizando Pandas. El EDA es un paso crucial en el proceso de análisis de datos, donde llegamos a conocer nuestros datos, entendemos sus características y descubrimos percepciones iniciales. Utilizaremos un DataFrame, `df`, cargado desde el conjunto de datos \"Advertising.csv\" como ejemplo para realizar varios análisis exploratorios. Comencemos cargando el conjunto de datos y echando un vistazo a su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"../datasets/Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffeed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9482a5",
   "metadata": {},
   "source": [
    "### Información meta\n",
    "\n",
    "`shape, columns, dtypes, info, describe`\n",
    "\n",
    "Cuando trabajas con datos en un DataFrame, es crucial entender las características básicas y la estructura del conjunto de datos. Para obtener percepciones sobre los datos, podemos recuperar información meta sobre el DataFrame. Esta información incluye detalles como la forma del DataFrame, nombres de columnas, tipos de datos, información general y un resumen estadístico de los datos.\n",
    "\n",
    "En esta sección, exploraremos cómo usar varias funciones de Pandas para obtener información meta esencial sobre tu DataFrame. Este conocimiento te ayudará a comprender mejor y preparar tus datos para el análisis y la visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21068edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the DataFrame (rows, columns)\n",
    "data_shape = df.shape\n",
    "print(f\"Shape of the DataFrame: {data_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323267f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "column_names = df.columns\n",
    "print(f\"Column Names: {column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of each column\n",
    "data_types = df.dtypes\n",
    "print(f\"Data Types:\\n{data_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c14a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Information about the DataFrame\n",
    "data_info = df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "data_summary = df.describe()\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7886577",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Previsualización\n",
    "Antes de sumergirte en un análisis y manipulación profundos de tu conjunto de datos, a menudo es útil obtener un vistazo rápido de cómo se ven los datos. Pandas proporciona dos métodos útiles, `head()` y `tail()`, para ayudarte a previsualizar el principio y el final de tu DataFrame.\n",
    "\n",
    "En esta sección, exploraremos cómo usar estos métodos para mostrar un subconjunto de tus datos, facilitando la comprensión de la estructura y el contenido de tu DataFrame. Estas herramientas simples pero poderosas son el primer paso para familiarizarte con tus datos, permitiéndote identificar cualquier patrón o problema inmediato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209b64c",
   "metadata": {},
   "source": [
    "`head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6520b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Por defecto, `head` me muestra las primeras 5 filas, puedo ver algunas más o menos pasando un número como parámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9283b27",
   "metadata": {},
   "source": [
    "`tail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71547174",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Ordenar un dataframe\n",
    "Organizar y ordenar tus datos es una parte fundamental del análisis de datos. En esta sección, exploraremos cómo ordenar un DataFrame usando la biblioteca Pandas. Al ordenar datos, puedes obtener valiosas percepciones, identificar tendencias y hacer que tus datos sean más accesibles para el análisis.\n",
    "\n",
    "Cubriremos varios escenarios, como ordenar por una o más columnas, en orden ascendente o descendente, y seleccionar columnas específicas para ver. Entender cómo organizar tus datos de manera efectiva puede mejorar significativamente tu capacidad para extraer información significativa de ellos.\n",
    "\n",
    "Sumergámonos en las diferentes formas de ordenar y organizar tus datos usando Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from a CSV file\n",
    "df = pd.read_csv(\"../datasets/avocado_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c76851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by a single column in descending order (most recent year first)\n",
    "df.sort_values(by=\"year\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dfbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by multiple columns in descending order (year and region)\n",
    "df.sort_values(by=[\"year\", \"region\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by a single column in descending order (region)\n",
    "df.sort_values(by=\"region\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80bf450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by a single column in descending order (year)\n",
    "df.sort_values(by=\"year\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128be49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns (year and region) after sorting\n",
    "df.sort_values(by=\"year\", ascending=False)[[\"year\", \"region\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of column names to create a subset of columns\n",
    "subset_columns = list(df.columns)[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset of columns using the list of column names\n",
    "df[subset_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd2f0d",
   "metadata": {},
   "source": [
    "`sample`\n",
    "\n",
    "En el análisis de datos, a menudo es esencial trabajar con un subconjunto representativo de tu conjunto de datos para varios propósitos, como exploración de datos, pruebas o entrenamiento de modelos. Pandas proporciona el método `sample` para facilitar el muestreo aleatorio de filas de un DataFrame. Este método te permite obtener filas aleatorias o una fracción específica de tus datos, convirtiéndolo en una herramienta valiosa para el análisis estadístico y tareas de aprendizaje automático. En esta sección, exploraremos cómo usar el método `sample` para extraer muestras aleatorias de un DataFrame y entender sus diversas opciones y aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afaa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling a random single row from the DataFrame\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling a random fraction (20%) of rows from the DataFrame\n",
    "df.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4bc9c",
   "metadata": {},
   "source": [
    "`display`\n",
    "Cuando trabajas con Jupyter Notebook o JupyterLab, puedes usar la función `display` para renderizar DataFrames de Pandas en un formato más visualmente atractivo e interactivo. Aunque la visualización tabular predeterminada de Pandas es informativa, la función `display` proporciona opciones adicionales de flexibilidad y personalización.\n",
    "\n",
    "Al usar `display`, puedes aprovechar las capacidades mejoradas de formato de tablas de los entornos Jupyter, incluyendo columnas ordenables, diseño adaptable y una representación visual mejorada de tus datos. Es especialmente útil cuando se trata con conjuntos de datos más grandes o cuando quieres presentar tus datos de una manera más limpia e interactiva para la exploración de datos o informes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ae834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame using the display function (equivalent to print)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7446f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Valores NaN\n",
    "\n",
    "En el análisis de datos, la falta de datos es una ocurrencia común y puede impactar significativamente la precisión y fiabilidad de tus análisis. Una forma de representar datos faltantes en Pandas y muchas otras bibliotecas de análisis de datos es mediante el uso del valor especial \"NaN\", que significa \"Not A Number\" (No Es Un Número).\n",
    "\n",
    "NaN es esencialmente un marcador de posición para puntos de datos faltantes o indefinidos, y generalmente se trata como un valor de punto flotante. Esto permite que Pandas trabaje con datos faltantes mientras mantiene los tipos de datos dentro de un DataFrame.\n",
    "\n",
    "Manejar los valores NaN es un aspecto crucial de la limpieza y preprocesamiento de datos, ya que puede afectar los cálculos estadísticos, visualizaciones y modelos de aprendizaje automático. En esta sección, exploraremos varias técnicas y funciones en Pandas para tratar con datos faltantes y asegurar que tu análisis de datos produzca resultados precisos y significativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = pd.isnull(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "missing_counts = missing_values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count columns with missing values\n",
    "columns_with_missing = missing_counts[missing_counts > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeafabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all columns have missing values\n",
    "all_columns_missing = missing_counts.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of missing values\n",
    "total_missing_values = missing_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(\"Missing Values in Each Column:\\n\", missing_counts)\n",
    "print(\"\\nNumber of Columns with Missing Values:\", columns_with_missing)\n",
    "print(\"All Columns Have Missing Values:\", all_columns_missing)\n",
    "print(\"\\nTotal Missing Values in the DataFrame:\", total_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ceff9",
   "metadata": {},
   "source": [
    "## Business Challenge: Analyzing Avocado Sales\n",
    "\n",
    "En este ejercicio, nos sumergiremos en un escenario empresarial del mundo real relacionado con datos de ventas de aguacates. El consumo de aguacates ha aumentado en los últimos años, y has sido contratado por una cadena de tiendas de comestibles regionales para obtener percepciones de sus datos de ventas. La tienda quiere entender las tendencias, estrategias de precios y factores que influyen en las ventas de aguacates para tomar decisiones informadas y mejorar la rentabilidad.\n",
    "\n",
    "### Introducción al Conjunto de Datos de Aguacate\n",
    "\n",
    "El conjunto de datos con el que trabajarás contiene información sobre ventas de aguacates en diferentes regiones de Estados Unidos. Los datos incluyen detalles como fecha, precio promedio, volumen total vendido, región y más.\n",
    "\n",
    "**Tu Misión:** Utilizando Pandas, realiza un análisis comprensivo para responder preguntas críticas de negocio. Aquí hay algunas de las tareas que necesitarás cumplir:\n",
    "\n",
    "### Tareas:\n",
    "\n",
    "1. **Carga de Datos:** Comienza cargando el conjunto de datos de Aguacate (`avocado.csv`) en un DataFrame de Pandas.\n",
    "\n",
    "2. **Exploración de Datos:** Realiza un análisis exploratorio de datos para entender la estructura del conjunto de datos, incluyendo el número de filas y columnas, tipos de datos y cualquier valor faltante.\n",
    "\n",
    "3. **Análisis de Series de Tiempo:** Analiza las ventas de aguacates a lo largo del tiempo. Identifica tendencias estacionales y determina si hay patrones relacionados con los precios y el volumen.\n",
    "\n",
    "4. **Análisis Regional:** Investiga las ventas de aguacates por región. ¿Qué regiones son las mejores en términos de volumen de ventas y precios? ¿Hay regiones que requieren atención específica?\n",
    "\n",
    "5. **Tendencias de Precios y Volumen:** Determina cómo los cambios en los precios de aguacates afectan el volumen de ventas. ¿Hay puntos de precio que impulsan ventas más altas o más bajas?\n",
    "\n",
    "6. **Elasticidad del Precio:** Calcula la elasticidad del precio de la demanda de aguacates. Esto ayudará a la tienda a entender cuán sensibles son las ventas a cambios de precios.\n",
    "\n",
    "7. **Recomendaciones:** Basado en tu análisis, proporciona recomendaciones accionables a la cadena de tiendas de comestibles. ¿Qué estrategias de precios deberían considerar? ¿Hay regiones específicas donde pueden mejorar las ventas?\n",
    "\n",
    "### Para Empezar:\n",
    "\n",
    "Para comenzar, carga el conjunto de datos de Aguacate y comienza tu exploración de datos. Utiliza Pandas para la limpieza de datos, visualización y análisis. A medida que progreses a través de las tareas, documenta tus hallazgos e insights para presentarlos a la gerencia de la cadena de tiendas de comestibles.\n",
    "\n",
    "Recuerda, Pandas es una herramienta poderosa que puede ayudar a las empresas a tomar decisiones basadas en datos. Este ejercicio te dará experiencia práctica en análisis de datos y mostrará los valiosos insights que pueden extraerse de datos del mundo real.\n",
    "\n",
    "Ahora, sumérgete en el mundo de las ventas de aguacates y comienza a hacer recomendaciones basadas en datos para impulsar la rentabilidad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ef542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f352ca",
   "metadata": {},
   "source": [
    "## Resumen: Puntos Clave Sobre Pandas\n",
    "\n",
    "- **Pandas es una Biblioteca Poderosa:** Pandas es una biblioteca de Python versátil utilizada para trabajar con datos estructurados de manera eficiente.\n",
    "\n",
    "- **Construido sobre NumPy:** Está construido sobre NumPy, lo que lo hace increíblemente rápido y eficiente para la manipulación de datos.\n",
    "\n",
    "- **Ampliamente Utilizado:** Pandas es ampliamente adoptado por otras bibliotecas de datos y herramientas, convirtiéndolo en una parte fundamental del ecosistema de datos.\n",
    "\n",
    "- **Datos Tabulares:** Pandas sobresale en el manejo de datos tabulares, que consisten en filas y columnas.\n",
    "\n",
    "- **Python y Pandas Juntos:** Al trabajar con datos, a menudo usas tanto Python como Pandas en conjunto para alcanzar tus objetivos.\n",
    "\n",
    "### Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "- **Vista Previa de Datos:** Puedes previsualizar rápidamente tus datos usando métodos como `head()`, `tail()` y `sample()` para inspeccionar el principio, final o partes aleatorias de tu conjunto de datos.\n",
    "\n",
    "- **Visión General de Datos:** Los métodos `info()` y `describe()` proporcionan una visión general de tus datos, incluyendo tipos de datos y estadísticas descriptivas.\n",
    "\n",
    "- **Valores Únicos:** Usa `unique()` o `value_counts()` para encontrar valores únicos o contar ocurrencias en una columna.\n",
    "\n",
    "- **Ordenamiento:** Puedes ordenar tus datos usando el método `sort_values()`, lo cual es útil para organizar datos por columnas específicas.\n",
    "\n",
    "- **Subconjunto de Datos:** La selección de subconjuntos te permite seleccionar filas o columnas específicas. Usa corchetes (`[]`) para extraer columnas o filas basadas en condiciones.\n",
    "\n",
    "### Creando DataFrames\n",
    "\n",
    "- **Desde Listas de Diccionarios:** Puedes crear DataFrames a partir de listas de diccionarios, donde cada diccionario representa una fila.\n",
    "\n",
    "- **Desde Diccionarios con Listas:** Alternativamente, los DataFrames pueden ser creados a partir de diccionarios con listas como valores. Ten en cuenta asegurar que las listas tengan la misma longitud.\n",
    "\n",
    "- **Lectura de Datos:** Pandas proporciona funciones como `read_csv()` para leer datos de varias fuentes, como archivos CSV, URLs, bases de datos SQL, archivos Excel, y más. Puedes usar tanto rutas absolutas como relativas, e incluso cargar datos desde fuentes remotas como repositorios de GitHub.\n",
    "\n",
    "Estos son algunos de los conceptos y operaciones esenciales en Pandas, permitiéndote manipular y explorar tus datos de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f340806",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Pandas cheat sheet\n",
    "```python\n",
    "df.head() # prints the head, default 5 rows\n",
    "df.tail() # set the tail, default 5 rows\n",
    "df.describe() # statistical description\n",
    "df.info() # df information\n",
    "df.columns # show column\n",
    "df.index # show index\n",
    "df.dtypes # show column data types\n",
    "df.plot() # make a plot\n",
    "df.hist() # make a histogram\n",
    "df.col.value_counts() # counts the unique values ​​of a column\n",
    "df.col.unique() # returns unique values ​​from a column\n",
    "df.copy() # copies the df\n",
    "df.drop() # remove columns or rows (axis=0,1)\n",
    "df.dropna() # remove nulls\n",
    "df.fillna() # fills nulls\n",
    "df.shape # dimensions of the df\n",
    "df._get_numeric_data() # select numeric columns\n",
    "df.rename() # rename columns\n",
    "df.str.replace() # replace columns of strings\n",
    "df.astype(dtype='float32') # change the data type\n",
    "df.iloc[] # locate by index\n",
    "df.loc[] # locate by element\n",
    "df.transpose() # transposes the df\n",
    "df.T\n",
    "df.sample(n, frac) # sample from df\n",
    "df.col.sum() # sum of a column\n",
    "df.col.max() # maximum of a column\n",
    "df.col.min() # minimum of one column\n",
    "df[col] # select column\n",
    "df.col\n",
    "df.isnull() # null values\n",
    "df.isna()\n",
    "df.notna() # not null values\n",
    "df.drop_duplicates() # remove duplicates\n",
    "df.reset_index(inplace=True) # reset the index and overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-jefferson",
   "metadata": {},
   "source": [
    "## Más material\n",
    "\n",
    "* [Read the docs!](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* [Cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "* [Exercises to practice](https://github.com/guipsamora/pandas_exercises)\n",
    "* [More on merge, concat, and join](https://realpython.com/pandas-merge-join-and-concat/#pandas-join-combining-data-on-a-column-or-index). And [even more!](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "## Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Avocado dataset into a Pandas DataFrame\n",
    "df = pd.read_csv(\"../datasets/avocado_kaggle.csv\")\n",
    "\n",
    "# Data Exploration\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Time-Series Analysis\n",
    "# Convert the 'Date' column to a datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group data by date to analyze trends\n",
    "monthly_sales = df.groupby(df['Date'].dt.to_period(\"M\"))['Total Volume'].sum()\n",
    "monthly_sales.plot(figsize=(12, 6))\n",
    "plt.title('Monthly Avocado Sales Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Volume Sold')\n",
    "plt.show()\n",
    "\n",
    "# Regional Analysis\n",
    "# Identify the top-performing regions in terms of sales volume and pricing\n",
    "top_regions_volume = df.groupby('region')['Total Volume'].sum().nlargest(5)\n",
    "top_regions_price = df.groupby('region')['AveragePrice'].mean().nlargest(5)\n",
    "\n",
    "print(\"Top 5 Regions by Sales Volume:\")\n",
    "print(top_regions_volume)\n",
    "print(\"\\nTop 5 Regions by Average Price:\")\n",
    "print(top_regions_price)\n",
    "\n",
    "# Price and Volume Trends\n",
    "# Analyze how changes in avocado prices affect sales volume\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df['AveragePrice'], df['Total Volume'], alpha=0.5)\n",
    "plt.title('Price vs. Volume')\n",
    "plt.xlabel('Average Price')\n",
    "plt.ylabel('Total Volume Sold')\n",
    "plt.show()\n",
    "\n",
    "# Price Elasticity\n",
    "# Calculate the price elasticity of demand\n",
    "df['Price Elasticity'] = df['Total Volume'] / df['AveragePrice']\n",
    "df['Price Elasticity'].describe()\n",
    "\n",
    "# Recommendations\n",
    "# Provide recommendations based on analysis\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"1. Focus on regions with high sales volume, such as\", top_regions_volume.index[0])\n",
    "print(\"2. Monitor price elasticity closely and consider adjusting prices strategically.\")\n",
    "print(\"3. Analyze seasonal trends for potential marketing campaigns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.766px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
