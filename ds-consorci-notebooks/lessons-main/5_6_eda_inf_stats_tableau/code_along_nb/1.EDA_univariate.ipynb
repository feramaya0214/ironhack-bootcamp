{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affefcbc-d980-401d-a342-5bf3ae125480",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (EDA) with Housing Price Dataset\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a crucial step in the data analysis pipeline. It helps us understand the data, discover patterns, spot anomalies, and frame hypotheses. In this lesson, we'll use a housing price dataset to explore various EDA techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3e65f-dcb9-43ea-8dc7-74829a6204ee",
   "metadata": {},
   "source": [
    "## Initial Steps for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65704bf4-cf6e-443f-af0d-2e5fcac5a5a9",
   "metadata": {},
   "source": [
    "The initial steps for data analysis in Python include:\n",
    "\n",
    "1. **Data Acquisition:** This involves gathering data from various sources such as local files, databases, APIs, websites, etc.\n",
    " \n",
    "2. **Loading the Data:** Common formats to consider are CSV (Comma Separated Values), JSON, XLS, HTML, XML, and more.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):** EDA is a systematic approach to initial data inspection. It leverages **descriptive analysis** techniques to understand the data better, identify outliers, highlight significant variables, and generally uncover underlying data patterns. Additionally, EDA helps in organizing the data, spotting errors, and assessing missing values.\n",
    "\n",
    "4. **Data Cleaning:** It's crucial to check the available data and perform tasks such as removing empty columns, standardizing terms, imputing missing data where appropriate, and more.\n",
    "\n",
    "5. After cleaning, you should conduct a more in-depth exploratory data analysis to further understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350b116-324f-4dee-b416-9c98cbdb81c6",
   "metadata": {},
   "source": [
    "## Methods in EDA\n",
    "\n",
    "EDA methodologies can be broadly categorized into:\n",
    "\n",
    "- **Numerical Measures:** These can include coefficients, frequency counts, and other statistical metrics.\n",
    "  \n",
    "- **Visual Representations:** Examples are histograms, scatter plots, pie charts, and more.\n",
    "\n",
    "Additionally, based on the number of variables in focus, methods can be:\n",
    "\n",
    "- **Univariate:** Describing the characteristics of a single variable at a time.\n",
    "  \n",
    "- **Bivariate:** Analyzing the relationship between two variables, either in tandem or understanding one variable based on the other (examining the influence of one independent variable in relation to the dependent variable).\n",
    "  \n",
    "- **Multivariate:** An extension of bivariate analysis but for multiple variables. It explores the relationships among them or the impact of two or more independent variables (sometimes along with associated variables or covariates) on one or more dependent variables.\n",
    "\n",
    "**Note**\n",
    "It's crucial to ensure that all our analytical methods are tailored to the type of variable under consideration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67de913-bcf2-4628-89c0-94fc3ce4535d",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "Before we dive into EDA, let's gather our data. In this case, we will load our dataset and take a quick look at its structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c874862-45f3-4242-b1b7-864ba3c4ceac",
   "metadata": {},
   "source": [
    "The dataset can be found [here](https://raw.githubusercontent.com/data-bootcamp-v4/data/main/housing_price_eda.csv) and the information about the dataset [here](https://github.com/data-bootcamp-v4/data/blob/main/housing_price_dataset_info.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a189e-9d1d-4d12-bc5c-33f50c4de1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e6c16-b2a9-48e2-a436-f45846226e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the housing price dataset (assuming the file name is \"housing_price.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/housing_price_eda.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca70225-3478-4642-a093-13a5e35a5770",
   "metadata": {},
   "source": [
    "## Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ec05d-e1cb-4fce-9254-3971ac438a5b",
   "metadata": {},
   "source": [
    "Before diving into the specifics of univariate analysis, it's essential to get acquainted with our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cee01d-cdc8-4407-80e0-6ce2a8d4405e",
   "metadata": {
    "id": "f0BcwWCfkTQR",
    "outputId": "72c16c61-79a9-4309-c177-c24529bbc3cb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c013ad8-b766-425c-99c1-e862955b22f1",
   "metadata": {
    "id": "7-elp1qykTQS"
   },
   "source": [
    "### Exploring numerical and categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e855ee3-153c-49f6-9fc2-5ab6f7105a7e",
   "metadata": {},
   "source": [
    "We'll explore numerical and categorical variables, and create two dataframes, one for each type of variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f86af-3b6b-4b05-983e-cf089d73c4ba",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- **Numerical variables**: These can encompass both quantitative and qualitative information. Often, discrete numerical variables with limited distinct values hint at qualitative (categorical) variable encoded as numbers.\n",
    "\n",
    "- **Object variables**: Typically, these consist of qualitative data, numeric data in a String format, or data that might not be directly relevant to the analysis. Examples include identifiers like 'ID' numbers or 'Names'. Variables with a broad range of unique values, especially in string format, often fall into this category. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8c395-f7b8-48c5-8b7c-1069904e1f1b",
   "metadata": {
    "id": "wlZ_7m1SkTQS",
    "outputId": "14ec1484-e49d-4e7f-c571-83aadf41192d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "337a95b8-8ce8-4487-be38-d0c3515c981d",
   "metadata": {},
   "source": [
    "Decide based on domain knowledge and the above explorations which numerical columns are better as categorical\n",
    " and vice versa. \n",
    " \n",
    " For demonstration purposes, let's assume the *potential_categorical_from_numerical* are categorical, even though this might not be the case in a real scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d625e-3a50-4e6e-818a-d4794ca0e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f7e96c-c467-4757-b66e-173e4eb2484b",
   "metadata": {
    "id": "Cu1COqyKkTQS"
   },
   "source": [
    "As previously mentioned during the data cleaning phase, it's essential to also explore **Data Typing/Formatting** to ensure data is in the correct type or format, **Duplicates** to check and handle any repeated data points, **Missing Values** to identify and address any null or missing data, **Categorical Variables** to examine the unique categories and their distributions and check whether they need cleaning (example: for gender, values such as M, F, Masculine, masculine, Femenine etc.), same for numerical data, **Outliers** to identify and decide how to handle extreme values etc.\n",
    "By exploring this, we can proceed with proper data cleaning. \n",
    "\n",
    "We won't be delving into this now, as we already saw it in data cleaning lessons (expect for outliers, which we'll be reviewing later in this lesson). We'll just clean quickly null values, so we can focus in univariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc70578-64f5-468e-8896-96e4083f452f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af3189-a8d2-4e16-9ace-40dae6c3aa7c",
   "metadata": {},
   "source": [
    "\n",
    "### Checking for Missing Data\n",
    "\n",
    "Missing data can influence our analysis. It's essential to identify and handle them appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51a035-a6da-4eac-96c3-60e503c429be",
   "metadata": {
    "id": "7sVQJcKYkTQS",
    "outputId": "4cb96bcb-ee40-497e-df6c-93d10293c8a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6b581e-8474-4253-9c22-e0335aed25d7",
   "metadata": {},
   "source": [
    "## Univariate Analysis\n",
    "\n",
    "Univariate analysis, as its name suggests, concentrates on one variable at a time, giving us a deep understanding of its characteristics. This fundamental step in Exploratory Data Analysis (EDA) lays the groundwork for subsequent analyses involving multiple variables. Let's explore various techniques for both categorical and numerical variables.\n",
    "\n",
    "**Categorical variables**:\n",
    "- Frequency tables. Counts and proportions.\n",
    "- Visualizations: Bar charts, pie charts\n",
    "\n",
    "**Numerical variables**: \n",
    "- Measures of centrality: Mean, median, mode\n",
    "- Measures of dispersion: Variance,  standard deviation, minimum, maximum, range, quantiles\n",
    "- Shape of the distribution: Symmetry and kurtosis\n",
    "- Visualizations: Histograms, box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0d3b7-3fe9-48d8-b3e4-c2f841a47317",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf113ec-fbb9-45e5-abe8-6c265da2497c",
   "metadata": {},
   "source": [
    "Categorical variables represent categories or labels, like types or groups. Analyzing categorical data involves understanding the frequency or proportion of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f37be-7b05-41b9-8377-ab218c997be4",
   "metadata": {},
   "source": [
    "#### Frequency Tables\n",
    "\n",
    "Frequency tables are tabular representations that display the number of occurrences of each category. They help in understanding the distribution of categories in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d09bd-c182-431c-aede-85d7ab4b128b",
   "metadata": {},
   "source": [
    "In python, we can use:\n",
    "- `value_counts()`\n",
    "- `pd.crosstab()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec4272-a4ec-41ad-a0f7-96e5596f4e7a",
   "metadata": {},
   "source": [
    "Let's consider *MSZoning* as our categorical variable of interest, which represents the general zoning classification of the sale.\n",
    "\n",
    "We'll look at `value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cf903-41dd-4438-ae70-a1969d8a1d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e961c0c-db36-446d-8650-b311ce9304ad",
   "metadata": {},
   "source": [
    "The frequency table gives the count of each zoning type, while the proportion table provides the percentage representation of each category in the dataset. This helps to quickly identify dominant and minority categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b83e68-77ac-4bc2-9223-58e7c7a1c4ea",
   "metadata": {},
   "source": [
    "Let's look at `pd.crosstab()`. The crosstab function can be useful to compute a cross-tabulation of two (or more) factors. Here, it's used to count the occurrences of each 'MSZoning' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc18040-faba-456a-af59-ce4056895c44",
   "metadata": {
    "id": "Llf1vw9OkTQc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "221f4e3d-f13e-4f0f-8cb9-aa6ddea5766a",
   "metadata": {},
   "source": [
    "The crosstab table displays the number of occurrences of each 'MSZoning' type, just like the frequency table. Computing the proportion table showcases the relative percentage of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290af1f-d89b-4101-88b9-9d2b1167225a",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "\n",
    "Visualizations offer a more intuitive understanding of categorical data distribution. Bar charts and pie charts are common methods to visually represent categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4d984-11c1-4efb-b506-ad89e4b7ef99",
   "metadata": {},
   "source": [
    "##### Bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b92e9e-7767-49bf-8ead-2c678420dc7b",
   "metadata": {},
   "source": [
    "Bar charts can display the frequency or proportion of each category using bars of varying lengths. Here, the same data is visualized using three different methods: `sns.barplot()` and `sns.countplot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f96a6-9b0a-4a5a-baec-079d7596cffa",
   "metadata": {},
   "source": [
    "Let's see how to use the `sns.barplot()` function with the result from `value_counts()` and `pd.crosstab()`. We should expect the same plot for both following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cdd7c-66f2-477f-a1b4-3d6f1eefbacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eceded8-ecaf-49cd-a346-12aca1c18e03",
   "metadata": {},
   "source": [
    "Using matplotlib, would just be:\n",
    "\n",
    "```python\n",
    "my_table.plot.bar()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba251e5-b2b8-4156-820d-9667dcaa5c3b",
   "metadata": {},
   "source": [
    "##### Countplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b3a6b-42de-45e4-b4f2-aa617c5fc117",
   "metadata": {},
   "source": [
    "A countplot is a type of bar plot in Seaborn that displays the count of occurrences of unique values in a categorical column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e30ca-29e8-4cbc-89e2-046181926da7",
   "metadata": {
    "id": "uFGdT_xekTQd"
   },
   "source": [
    "Same result now as the *bar plot* since it just assumes Y axis is the count of frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784cb76-f0e0-47b4-a86c-ad2cd41bf45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e6876a-720c-4eb6-9af1-ac5e7243f7e1",
   "metadata": {},
   "source": [
    "##### Pie charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106aa57-3fb5-42d9-81d1-360b1c97f73c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Pie charts provide a circular representation of the data, showing the proportion of each category as slices of a pie. However, they can be challenging to interpret when there are many categories or when categories have similar proportions.\n",
    "\n",
    "Seaborn, as of 2023, does not have a dedicated function for pie charts. Pie charts are more commonly created using `matplotlib`, which Seaborn is built upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e20290-b4bf-488e-805e-fec086d5c7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a9ff20-e1cc-49b3-9f5e-09285825f8f4",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a1b5f-2bab-4374-b15e-7f883ed1fa8b",
   "metadata": {},
   "source": [
    "Numerical variables are quantitative, and their values can be measured. Analyzing numerical data involves understanding its distribution, central tendency, and variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907a5ab-d9ea-44bd-9b82-1ec70ecf2125",
   "metadata": {},
   "source": [
    "\n",
    "#### Summary Statistics\n",
    "\n",
    "**Centrality and Dispersion Measures**\n",
    "\n",
    "Let's start by getting some basic statistics on our dataset to understand its scale, centrality, and spread.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4650d4c-4e31-4fb0-9abc-3ba9c40c2037",
   "metadata": {
    "id": "ONytB4d0kTQW"
   },
   "source": [
    "- The `.describe()` method provides key statistics for numerical columns (by default) in a dataframe, excluding NaN values; although it primarily targets numeric data, the `include` parameter allows for the selection of other data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a5b1f-12f9-4fa8-8adb-c92f4ca08bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86919e49-bc58-4e18-888e-11e1e9ca7685",
   "metadata": {},
   "source": [
    "#### More Centrality and Dispersion Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a24929-1526-4de1-9819-b099dc5bce9b",
   "metadata": {},
   "source": [
    "Now, suppose we want to calculate individual statistical measures without using the `.describe()` method. Here are some ways to do it:\n",
    "\n",
    "- `df[column].mean()`: Computes the mean of the selected column.\n",
    "- `df[column].median()`: Calculates the median of the selected column.\n",
    "- `df[column].mode()`: Identifies the mode of the selected column.\n",
    "- `df[column].std()`: Determines the standard deviation of the selected column.\n",
    "- `df[column].var()`: Computes the variance of the selected column.\n",
    "- `df[column].min()`: Finds the minimum value in the selected column.\n",
    "- `df[column].max()`: Finds the maximum value in the selected column.\n",
    "- `df[column].count()`: Counts the number of non-NaN entries in the selected column.\n",
    "\n",
    "In these examples, replace `column` with the name of the column you want to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec8229-d147-4723-b60c-2d86fda0f25c",
   "metadata": {},
   "source": [
    "For this section, we'll focus on 'SalePrice' as our numerical variable of interest, which represents the price at which the house was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53eced5-6cdd-46ff-8d33-7bd994acdc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db5c868-7c18-4615-af3c-59738959e533",
   "metadata": {},
   "source": [
    "#### Shape of the Distribution\n",
    "\n",
    "Skewness and kurtosis provide insights into the shape of the data distribution. Skewness indicates the asymmetry, and kurtosis tells about the \"tailedness\" or how peaked the distribution is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4274cb-a96d-4a55-9320-543c5647d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befeeb5b-0b95-4352-8670-2e7e948ab56a",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "\n",
    "Visual tools like histograms and box plots offer insights into the distribution, variability, and potential outliers in numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06648e1c-7968-4dae-8e9c-21541ad6a03b",
   "metadata": {},
   "source": [
    "##### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953101be-e2d6-4155-970a-c26b478ab591",
   "metadata": {},
   "source": [
    "Histograms display the frequency distribution of a dataset. The height of each bar represents the number of data points in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e684002-928b-46b7-ba9d-2315819d96b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "042e4152-a538-41c5-a82a-db95d173e561",
   "metadata": {},
   "source": [
    "##### Box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769335b7-0e7f-4509-b2f0-54b4ef6e9cf5",
   "metadata": {},
   "source": [
    "Box plots, or whisker plots, showcase the central 50% of the data (interquartile range), potential outliers, and other statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643b1a3-2fef-4bca-a30f-b063fc42ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9ded74-b151-42d6-b68e-3329040cdc87",
   "metadata": {},
   "source": [
    "## Converting continuous to discrete variables: Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95362e46-0cda-49e5-a48c-ec56af5cc535",
   "metadata": {},
   "source": [
    "Discretization is the process of converting continuous variables into discrete ones by creating a set of contiguous intervals (or bins) and then categorizing the variables into these intervals. This can be particularly useful when you want to categorize a continuous variable into different groups based on ranges. Note that we usually lose information in this process.\n",
    "\n",
    "For our dataset, let's take the 'SalePrice' column, which is continuous, and discretize it into categories like 'Low', 'Medium', 'High', and 'Very High'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b2bd0-7277-44d5-92a9-28f63ef10eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed3b58c-917a-455a-98f8-8ebc02f00cfd",
   "metadata": {},
   "source": [
    "Another useful option is **discretizing by quantiles**. This means dividing the data into intervals based on specific quantile values. This ensures that each bin has (approximately) the same number of data points. The `pandas` library provides a convenient method, `qcut()`, for this purpose.\n",
    "\n",
    "Discretizing by quantiles can be particularly useful when you want to create categories that represent relative rankings (like low, medium, high, etc.) based on the distribution of the data, rather than fixed numeric ranges.\n",
    "\n",
    "**Step 1**: Choose the number of quantiles (or bins). For example, if you want quartiles, you would choose 4 bins. \n",
    "\n",
    "**Step 2**: Use the `qcut()` function from `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd354287-f6b3-4e4a-a4a6-dcc51859b069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d1e65ac-595c-433e-8a60-44a3c3d4749d",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 💡 Check for understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59999a74-d893-4b18-b2f0-3dd9633e36b7",
   "metadata": {},
   "source": [
    "Discretize the '1stFlrSF' column (first-floor square feet) into three categories: 'Small', 'Medium', 'Large'. Set the bins such that 'Small' includes sizes up to the 33rd percentile, 'Medium' includes sizes from the 33rd to the 66th percentile, and 'Large' includes sizes from the 66th percentile onward. How many houses fall into each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740fb35-abfe-4b88-b007-abf6b62a5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e27b3-bb94-4400-97a9-483df3ab1e12",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, we've conducted a comprehensive univariate analysis:\n",
    "\n",
    "- For **categorical variables**, we visualized the distribution of our zoning classifications with bar and pie charts, backed by frequency tables.\n",
    "- For **numerical variables**, we explored the central tendencies, dispersions and shape of distribution of our sale prices, visualized through histograms and box plots.\n",
    "\n",
    "This analysis allows us to deeply understand each variable, laying a strong foundation for subsequent multivariate analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61c560-bd90-42a7-94a9-d19c50d1b25e",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 💡 Check for understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbdddec-f56b-44d0-87aa-a7570101d769",
   "metadata": {},
   "source": [
    "**Scenario**:\n",
    "Given the 'TotRmsAbvGrd' column (total rooms above ground), let's dive deep into its univariate characteristics.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **Data Aggregation**:\n",
    "    - Create a frequency table for 'TotRmsAbvGrd' to understand the distribution of the number of rooms in houses.\n",
    "    - Calculate the mean, median, mode, variance, and standard deviation of 'TotRmsAbvGrd'.\n",
    "\n",
    "2. **Visualization**:\n",
    "    - Plot a histogram for 'TotRmsAbvGrd' to understand its distribution.\n",
    "    - Plot a box plot for 'TotRmsAbvGrd' to visualize its central tendency, spread, and potential outliers.\n",
    "\n",
    "3. **Interpretation**:\n",
    "    - Is the distribution of the number of rooms skewed? If so, in which direction?\n",
    "    - Based on the histogram and box plot, what can you infer about the common number of rooms above ground in houses? \n",
    "    - Are there any noticeable outliers in the number of rooms? If so, are there more houses with unusually many rooms or unusually few?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95663d-01b7-47b7-9285-869b8792ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
